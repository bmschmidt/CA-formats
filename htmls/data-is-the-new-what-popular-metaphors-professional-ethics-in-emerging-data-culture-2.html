
    <head>
    <meta name="author" content="Luke Stark and Anna Lauren Hoffmann ">
    <title>Data Is the New What?  Popular Metaphors & Professional Ethics in Emerging Data Culture</title>
    <meta name="date" content="05.02.19">
    <meta name="shortauthor" content="Luke Stark and Anna Lauren Hoffmann ">
    <meta name="shorttitle" content="Data Is the New What?  Popular Metaphors & Professional Ethics in Emerging Data Culture">
    </head>
    
	<div class="entry print-only">
						 
		 
		<div class="post-2305 post type-post status-publish format-standard has-post-thumbnail hentry category-articles" id="post-2305">
			<!-- Show post on single page if option enabled -->

		
					<h6><em>Peer-Reviewed By: A<span lang="EN-CA" xml:lang="EN-CA">nonymous and Dr. Brian Beaton</span></em></h6>
<h6><em>Clusters: <a href="http://culturalanalytics.org/2018/01/data/">Data</a>,<a href="http://culturalanalytics.org/2018/11/infrastructure/"> Infrastructure</a></em></h6>
<h6><em>Article DOI: <a href="https://culturalanalytics.org/2019/05/data-is-the-new-what-popular-metaphors-professional-ethics-in-emerging-data-culture-2/">10.22148/16.036</a></em></h6>
<h6><em>PDF DOI: <a href="https://doi.org/10.31235/osf.io/2xguw">10.31235/osf.io/2xguw</a></em></h6>
<h6><em>Journal ISSN: 2371-4549</em></h6>
<h6><em>Cite: Luke Stark and Anna Lauren Hoffmann, "Data Is the New What? Popular Metaphors &amp;amp; Professional Ethics in Emerging Data Culture," Journal of Cultural Analytics. May 2, 2019. DOI: <a href="https://doi.org/10.31235/osf.io/2xguw">10.31235/osf.io/2xguw</a></em></h6>
<p> </p>
<p>A growing list of high-profile controversies involving the social impacts of artificial intelligence systems (AI), digital data collection and algorithmic analysis have forced difficult conversations around the ethics of data-intensive digital technologies and so-called "big data" research.<sup><a href="#footnote_0_2305" id="identifier_0_2305" class="footnote-link footnote-identifier-link" title="Author order is reverse-alphabetical and reflects equal contributions to the project by both authors. This work was supported by a grant from the Center for Technology, Society, and Policy at the University of California Berkeley. We would also like to thank Nick Seaver, Daniel Greene, Tanya E. Clement, Brian Beaton, Amelia Acker and an anonymous reviewer.">1</a></sup><sup><a href="#footnote_1_2305" id="identifier_1_2305" class="footnote-link footnote-identifier-link" title="Brent Mittelstadt, “Ethics of the Health-Related Internet of Things: a Narrative Review,” Ethics and Information Technology 19, no. 3 (September 15, 2017): 157–75, doi:10.1007/s10676-017-9426-4; A D I Kramer, J E Guillory, and J T Hancock, “Experimental Evidence of Massive-Scale Emotional Contagion Through Social Networks,” Proceedings of the National Academy of Sciences 111, no. 24 (June 17, 2014): 8788–90, doi:10.1073/pnas.1320040111; Michal Kosinski et al., “Manifestations of User Personality in Website Choice and Behaviour on Online Social Networks,” Machine Learning 95, no. 3 (October 19, 2013): 357–80, doi:10.1007/s10994-013-5415-y; Gillinder Bedi et al., “Automated Analysis of Free Speech Predicts Psychosis Onset in High-Risk Youths.,” Npj Schizophrenia 1 (January 1, 2015): 15030–30, doi:10.1038/npjschz.2015.30; Lemi Baruh and Mihaela Popescu, “Big Data Analytics and the Limits of Privacy Self-Management,” New Media &amp; Society 19, no. 4 (October 9, 2015): 579–96, doi:10.1177/1461444815614001.">2</a></sup>These incidents are directly relevant to newly coalescing cultures of "data science," an emergent field which seeks both to interpret and capitalize on the creation, collection, and processing of knowledge through large collections of digital data, often in conjunction with particular techniques like machine learning (ML).<sup><a href="#footnote_2_2305" id="identifier_2_2305" class="footnote-link footnote-identifier-link" title="Brian Beaton, Amelia Acker, Lauren Di Monte, Shivrang Setlur, Tonia Sutherland, and Sarah E Tracy, “Debating Data Science,” Radical History Review 2017, no. 127 (March 2, 2017): 133–48. doi:10.1215/01636545-3690918.">3</a></sup> The long list of recent public controversies, as Brian Beaton observes, lays bare data science's extant lack of direction regarding professional ethics or values.<sup><a href="#footnote_3_2305" id="identifier_3_2305" class="footnote-link footnote-identifier-link" title="Brian Beaton, “How to Respond to Data Science: Early Data Criticism by Lionel Trilling,” Information &amp; Culture: a Journal of History 51, no. 3 (August 2016): 352–72. doi:10.7560/IC51303.">4</a></sup></p>
<p>Various groups have ventured into this conceptual gap to advance principles or guidelines for doing ethical data science. In 2017, for example, digital organization Data for Democracy (D4D)<span class="emdash">—</span>in partnership with media conglomerate Bloomberg and open source platform BrightHive<span class="emdash">—</span>announced an effort to crowdsource a code of ethics for data scientists, seeking to "define values and priorities for overall ethical behavior, in order to guide a data scientist in being a thoughtful, responsible agent of change."<sup><a href="#footnote_4_2305" id="identifier_4_2305" class="footnote-link footnote-identifier-link" title="“Code of Ethics,” Data for Democracy, accessed June 2, 2018, http://datafordemocracy.org/projects/ethics.html.">5</a></sup>This recent focus on developing ethical codes for data science (alongside related areas such as AI/ML) suggests the field seeks to address its social impacts through discourses and processes of professional consolidation.<sup><a href="#footnote_5_2305" id="identifier_5_2305" class="footnote-link footnote-identifier-link" title="For an analysis of ethics statements in the AI context, see Daniel Greene, Anna Lauren Hoffmann, and Luke Stark (forthcoming), &quot;Better, nicer, clearer, fairer: A critical assessment of the movement for ethical artificial intelligence and machine learning,&quot; 52nd Hawaii International Conference on Systems Science.">6</a></sup> Yet such efforts raise further questions. What kind of work counts as "data science" in the first place? What are its aims and historical precursors? And what, if any, baseline ethical commitments bind disparately situated researchers, analysts, and (of course) professional data scientists?</p>
<p>As data science seeks to constitute itself as a professional field, these questions will continue to lurk in the background of efforts to articulate and codify data science's ethical commitments. In this paper, we examine one dimension of this conceptual terrain: the relevance and resonance of extant codes of professional and research ethics in<span class="emdash">—</span>and beyond<span class="emdash">—</span>domains related to computing, information science, and data analytics. The paper proceeds in four parts. In the first, we draw on work in the history and sociology of professional ethics to establish the (often fraught) relationship between ethical codes, professionalization, and moral responsibility, with a focus on ethics codes in domains conventionally allied with data science such as computing and information science. Second, we expand the domain of potentially relevant professional analogues by reviewing and drawing inspiration from many of the popular metaphors for "data"<span class="emdash">—</span>and by extension, the work of data scientists<span class="emdash">—</span>proliferating in both popular and academic settings.</p>
<p>In the third and fourth sections, we employ discourse analysis to assess two sets of professional ethics codes: one set rooted in conventionally allied domains like computing; the other derived from those professions evoked by the metaphors associated with data and data science. Through this discursive analysis, we develop a number of insights regarding the challenges and opportunities of developing a code of ethics for data science, and by extension the ambivalent role of data science as a profession within a broader tapestry of "data cultures."<sup><a href="#footnote_6_2305" id="identifier_6_2305" class="footnote-link footnote-identifier-link" title="Kath Albury et al., “Data Cultures of Mobile Dating and Hook-Up Apps: Emerging Issues for Critical Social Science Research,” Big Data &amp; Society 4, no. 2 (July 3, 2017): 205395171772095–11, 135, doi:10.1177/2053951717720950.">7</a></sup>With multiple metaphors for what "big data" is and can do, and multiple potentially relevant ethics codes scattered across different domains, data ethics is a field in flux. Collectively, these conversations represent an effort to better grapple with the consequences of the language we use for understanding and working with data<span class="emdash">—</span>"big" or otherwise<span class="emdash">—</span>today, and how our discourses around data cultures shape their material, cultural, and political impact.</p>
<h1 style="text-align: center;">Ethics Codes As/And Professional Cultures</h1>
<p>Codes of ethics are longstanding mechanisms through which groups of experts have sought to define themselves and their priorities as "professionals," or recognized members of particular professions.<sup><a href="#footnote_7_2305" id="identifier_7_2305" class="footnote-link footnote-identifier-link" title="Harold L Wilensky, “The Professionalization of Everyone?,” American Journal of Sociology 70, no. 2 (September 1964): 137–58.">8</a></sup>High-status professions such as doctors, lawyers and engineers pioneered professional ethics codes as early as the eighteenth century. Today, many other groups of experts<span class="emdash">—</span>from foresters to firefighters to astrologers<span class="emdash">—</span>have enacted these codes as signals, sometimes merely aspirational, of their professional status. Ongoing historical and sociological work in this area has shown such codes can and have served a range of valuable functions, from educating professionals and instilling positive group norms to setting benchmarks against which unethical behavior may be censured.<sup><a href="#footnote_8_2305" id="identifier_8_2305" class="footnote-link footnote-identifier-link" title="Mark S. Frankel, “Professional Codes: Why, How, and with What Impact?,” Journal of Business Ethics 8, no. 2 (1989): 109–15; Bruce R Gaumnitz and John C Lere, “A Classification Scheme for Codes of Business Ethics,” Journal of Business Ethics49 (2004): 329–35; Michael Davis, “The Ethics Boom: What and Why,” The Centennial Review 34, no. 2 (1990): 163–86.">9</a></sup><sup><a href="#footnote_9_2305" id="identifier_9_2305" class="footnote-link footnote-identifier-link" title="Gaumnitz and Lere, “A Classification Scheme for Codes of Business Ethics;” Muel Kaptein and Johan Wempe, “Twelve Gordian Knots When Developing an Organizational Code of Ethics,”Journal of Business Ethics 17, no. 8 (June 1998): 853–69.Alan Gewirth, “Professional Ethics: the Separatist Thesis,” Ethics 96, no. 2 (January 1986): 282–300; Andrew Abbott, “Professional Ethics,” American Journal of Sociology 88, no. 5 (March 1983): 855–85.">10</a></sup>Most important for present purposes, a profession's ethical code offers insight into how it collectively understands and seeks to modulate the distribution of obligations between individual practitioners, other individuals or stakeholders, and society more broadly.<sup><a href="#footnote_10_2305" id="identifier_10_2305" class="footnote-link footnote-identifier-link" title="Abbott, “Professional Ethics,” 856.">11</a></sup></p>
<p>In his survey of the history of professional ethics codes, Andrew Abbot demonstrates the ubiquity of such codes as a key element of industrial state/social formation, representing perhaps "the most concrete cultural form in which professions acknowledge their societal obligations."<sup><a href="#footnote_11_2305" id="identifier_11_2305" class="footnote-link footnote-identifier-link" title="Abbott, “Professional Ethics.”">12</a></sup>These codes do not arise in theoretical or conceptual vacuums. As Jacob Metcalf writes of research ethics, they represent "hard-won responses to major disruptions, especially medical and behavioral research scandals."<sup><a href="#footnote_12_2305" id="identifier_12_2305" class="footnote-link footnote-identifier-link" title="Jacob Metcalf, “Ethics Codes: History, Context, and Challenges,” Council for Big Data, Ethics, and Society, November 9, 2014.">13</a></sup>In addition, ethics codes are enforced most often when ethical infractions or controversies are highly visible. As Abbot notes, "general public service obligations are extremely important as claims but extremely vague as rules."<sup><a href="#footnote_13_2305" id="identifier_13_2305" class="footnote-link footnote-identifier-link" title="Metcalf, “Ethics Codes: History, Context, and Challenges,” 863.">14</a></sup>Mark Frankel likewise notes a relationship between "professions' pursuit of autonomy,<sup><a href="#footnote_14_2305" id="identifier_14_2305" class="footnote-link footnote-identifier-link" title="Frankel, “Professional Codes: Why, How, and with What Impact?”">15</a></sup>and the public's demand for accountability."<sup><a href="#footnote_15_2305" id="identifier_15_2305" class="footnote-link footnote-identifier-link" title="Frankel, “Professional Codes: Why, How, and with What Impact?,” 109.">16</a></sup> In view of this tension between visibility and vagueness, ethics codes often elide granular attention to professional activities, relying instead on informal everyday rules over which individual practitioners have some (albeit limited) control.</p>
<p>Fundamental to these debates is the question of whether a professional ethics code should be a fine-grained "how-to" manual or a set of broad principles to be inculcated into an individual. These questions are particularly evident in the history of engineering codes and engineering ethics.<sup><a href="#footnote_16_2305" id="identifier_16_2305" class="footnote-link footnote-identifier-link" title="Heinz C. Luegenbiehl, “Codes of Ethics and the Moral Education of Engineers,” Business Professional Ethics Journal2, no. 4 (1983): 41–61.">17</a></sup>For engineers, there remains a tension in the inherent definition of a profession as a group of experts explicitly set to serve the general public, and a profession's own interests as a particular group.<sup><a href="#footnote_17_2305" id="identifier_17_2305" class="footnote-link footnote-identifier-link" title="Michael Davis, “Thinking Like an Engineer: the Place of a Code of Ethics in the Practice of a Profession,” Philosophy &amp; Public Affairs 20, no. 2 (1991): 150–67.">18</a></sup>Extant conversations surrounding codes of ethics for computing mirror these disagreements.<sup><a href="#footnote_18_2305" id="identifier_18_2305" class="footnote-link footnote-identifier-link" title="Effy Oz, “Ethical Standards for Computer Professionals: a Comparative Analysis of Four Major Codes,” Journal of Business Ethics 12, no. 9 (September 1993): 709–26.">19</a></sup>As Metcalf observes, the current surge of practitioner and public interest in ethics of data science was paralleled by a flurry of work in the early 1990s by major international professional organizations<span class="emdash">—</span>including the Association of Computing Machinery (ACM) and the Institute of Electrical and Electronics Engineers (IEEE)<span class="emdash">—</span>to draft and implement ethics codes.<sup><a href="#footnote_19_2305" id="identifier_19_2305" class="footnote-link footnote-identifier-link" title="Metcalf, “Ethics Codes: History, Context, and Challenges.”">20</a></sup>Metcalf suggests ethics codes are often reactive, instituted in response to crises of professional confidence.<sup><a href="#footnote_20_2305" id="identifier_20_2305" class="footnote-link footnote-identifier-link" title="Metcalf, “Ethics Codes: History, Context, and Challenges.”">21</a></sup>Further, Effy Oz's assessment of ethics codes from four professional associations involving computing,<sup><a href="#footnote_21_2305" id="identifier_21_2305" class="footnote-link footnote-identifier-link" title="Oz,“Ethical Standards for Computer Professionals: a Comparative Analysis of Four Major Codes.”">22</a></sup>including the ACM, argued the lack of prioritization around moral obligations to various groups, common to professional ethics codes more generally, is especially pronounced in professional computing codes.<sup><a href="#footnote_22_2305" id="identifier_22_2305" class="footnote-link footnote-identifier-link" title="Don Gotterbarn and James H Moor, “Virtual Decisions: Video Game Ethics, Just Consequentialism, and Ethics on the Fly,” SIGCAS Computers and Society 39, no. 3 (December 2009): 27–42.">23</a></sup>As Frankel warns, ethics codes that fail to engage with broader social values and expectations risk becoming mere "political tools" for signaling moral virtue to society at large.</p>
<h1 style="text-align: center;">Data &amp; Data Science Metaphors</h1>
<p>If professional codes of ethics are often "hard-won responses to major disruptions," we should attend to the nature of the "disruption" in question. Doing so points towards previously underappreciated or overlooked ethical domains<span class="emdash">—</span>in this case, domains which help us better come to terms with the rise of the data scientist and an epistemological shift in how we produce, understand, and act on knowledge about the world.<sup><a href="#footnote_23_2305" id="identifier_23_2305" class="footnote-link footnote-identifier-link" title="Rob Kitchin, “Big Data, New Epistemologies and Paradigm Shifts,” Big Data &amp; Society 1, no. 1 (April 2014): 205395171452848–12, doi:10.1177/2053951714528481.">24</a></sup>Here, we identify additional domains of ethical consideration relevant to data ethics by turning to the metaphors we use to talk about data itself.</p>
<p>The metaphors we deploy to make sense of new tools and technologies serve the dual purpose of highlighting the novel by reference to the familiar, while also obscuring or abstracting away from some features of a given technology or practice<sup><a href="#footnote_24_2305" id="identifier_24_2305" class="footnote-link footnote-identifier-link" title="Mark Nunes, “Baudrillard in Cyberspace: Internet, Virtuality, and Postmodernity,” Style 29 (1995): 314–27; Sally Wyatt, “Danger! Metaphors at Work in Economics, Geophysiology, and the Internet,” Science, Technology, &amp; Human Values 29, no. 2 (August 18, 2016): 242–61, doi:10.1177/0162243903261947; Rowan Wilken, “An Exploratory Comparative Analysis of the Use of Metaphors in Writing on the Internet and Mobile Phones,” Social Semiotics 23, no. 5 (November 2013): 632–47, https://towardsdatascience.com/big-data-metaphors-we-live-by-98d3fa44ebf8.">25</a></sup><span class="emdash">—</span>as Teun A. van Dijk describes,<sup><a href="#footnote_25_2305" id="identifier_25_2305" class="footnote-link footnote-identifier-link" title="as Teun A. van Dijk,“Principles of Critical Discourse Analysis,” Discourse &amp; Society4, no. 2 (1993): 249–83; “Critical Discourse Analysis,” in The Handbook of Discourse Analysis, (West Sussex, UK: Wiley, 2015), 466–85.">26</a></sup>metaphors "are powerful means to make abstract mental models more concrete."<sup><a href="#footnote_26_2305" id="identifier_26_2305" class="footnote-link footnote-identifier-link" title="van Dijk, “Critical Discourse Analysis,” 473.">27</a></sup>In this way, metaphors<span class="emdash">—</span>Rowan Wilken notes<sup><a href="#footnote_27_2305" id="identifier_27_2305" class="footnote-link footnote-identifier-link" title="Rowan Wilken, “An Exploratory Comparative Analysis of the Use of Metaphors in Writing on the Internet and Mobile Phones,”Social Semiotics 23, no. 5 (November 2013): 632–47, doi:10.1080/10350330.2012.738999.">28</a></sup><span class="emdash">—</span>are never innocent; they "always influence and shape the meanings that are generated by, and the meanings which accumulate around, a given metaphor."<sup><a href="#footnote_28_2305" id="identifier_28_2305" class="footnote-link footnote-identifier-link" title="Wilken,“An Exploratory Comparative Analysis,&quot; 642.">29</a></sup>For example, as Dawn Nafus describes in the domain of data visualization,<sup><a href="#footnote_29_2305" id="identifier_29_2305" class="footnote-link footnote-identifier-link" title="Dawn Nafus,“Stuck Data, Dead Data, and Disloyal Data: the Stops and Starts in Making Numbers Into Social Practices,” Distinktion: Journal of Social Theory 15, no. 2 (June 17, 2014): 208–22, doi:10.1080/1600910X.2014.920266.">30</a></sup>the idea that data wants to be freed<span class="emdash">—</span>itself an offshoot of the earlier claim, "information wants to be free"<sup><a href="#footnote_30_2305" id="identifier_30_2305" class="footnote-link footnote-identifier-link" title="Stewart Brand, The Media Lab, (New York: Viking Penguin, 1987), 202.">31</a></sup><span class="emdash">—</span>masks the labor expended in "freeing" data, especially in cases where data, in the words of her research subjects, are "stuck" or "disloyal."</p>
<p>Cornelius Puschmann and Jean Burgess describe two predominating groups of metaphors around contemporary descriptions of data:1) data as a natural force to be controlled and 2) data as a resource to be consumed.<sup><a href="#footnote_31_2305" id="identifier_31_2305" class="footnote-link footnote-identifier-link" title="Cornelius Puschmann and Jean Burgess, &quot;Big Data, Big Questions| Metaphors of Big Data,&quot; International Journal of Communication 8 (2014).">32</a></sup>As a resource, the authors note data are analogized to "food and fuel," staple materials which "must be consumed to exist and to move forward rather than being consciously used."<sup><a href="#footnote_32_2305" id="identifier_32_2305" class="footnote-link footnote-identifier-link" title="Puschmann and Burgess, &quot;Big Data, Big Questions,&quot; 1700.">33</a></sup>As a force of nature, the authors observe data are often described as being in a liquid state: "allusion to water [or oil]" they write, "supports the notion that data is all at once essential, valuable, difficult to control, and ubiquitous."<sup><a href="#footnote_33_2305" id="identifier_33_2305" class="footnote-link footnote-identifier-link" title="Puschmann and Burgess, &quot;Big Data, Big Questions,&quot; 1699.">34</a></sup>From data lakes, rivers, and oceans to data floods, deluges, and tsunamis, these metaphors position data as something massive and volatile while also necessary to support human life.<sup><a href="#footnote_34_2305" id="identifier_34_2305" class="footnote-link footnote-identifier-link" title="The now-ubiquitous metaphor of “cloud” computing has similar resonances, though it captures data as vaporous—somewhere between an invisible gas and a suffocating liquid.">35</a></sup>As Deborah Lupton notes, however, liquid metaphors also tacitly work to forestall ethical or regulatory interventions by positioning data as ubiquitous, uncontrollable, and resistant to transparency or accountability.<sup><a href="#footnote_35_2305" id="identifier_35_2305" class="footnote-link footnote-identifier-link" title="Deborah Lupton, “Swimming or Drowning in the Data Ocean? Thoughts on the Metaphors of Big Data,” The Sociological Life, October 29, 2013.">36</a></sup></p>
<p>Both discursive strains<span class="emdash">—</span>data as force and resource<span class="emdash">—</span>point toward additional metaphors rooted in industrial production. As Sara M. Watson observes, many of our metaphors for data in the "knowledge economy" reference older industrial occupations.<sup><a href="#footnote_36_2305" id="identifier_36_2305" class="footnote-link footnote-identifier-link" title="Sara M. Watson, “Metaphors of Big Data,” DIS Magazine, May 28, 2016.">37</a></sup>Efforts to think through or propose strategies for managing data, in particular, rely on appeals to industrial imagery.<sup><a href="#footnote_37_2305" id="identifier_37_2305" class="footnote-link footnote-identifier-link" title="Kailash Awati and Simon Buckingham Shum, “Big Data Metaphors We Live by,” Towards Data Science, May 14, 2015.">38</a></sup>Descriptions of data as "toxic" or "radioactive" evoke images of massive nuclear facilities and radioactive waste management experts.<sup><a href="#footnote_38_2305" id="identifier_38_2305" class="footnote-link footnote-identifier-link" title="Cory Doctorow, “Why Personal Data Is Like Nuclear Waste,” The Guardian, January 15, 2008.)Metaphors referencing more quotidian forms of waste also point toward the similarly quotidian forms of work involved in data science: are those who work with data “rock stars” or “data janitors”—or both?((Lilly Irani, “Justice for ‘Data Janitors’,” Public Books, January 15, 2015.">39</a></sup></p>
<p>Curiously, as Tim Hwang and Karen Levy point out, often "people are nowhere to be found" in this landscape of data metaphors:<sup><a href="#footnote_39_2305" id="identifier_39_2305" class="footnote-link footnote-identifier-link" title="There is one notable—and noxious—analogy which does foreground people: “big data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so everyone claims they are doing it....” Posted to Facebook in 2013 by Dan Ariely, Professor at Duke University, the phrase has since been popularized in numerous blog posts, news articles, and talks. We have deliberately omitted this analogy, however, as we find it more problematic than insightful. Specifically, we do not wish to contribute to the sexualization of technological work—a process * often serves to exclude or marginalize women in STEM—or engage in the belittling of young persons’ sexual development. While other work may find constructive connections between sexual ethics and data ethics broadly (see, for example, work on the ethics of consent: Una Lee and Dann Toliver, Building Consentful Tech, Toronto, ON: And Also Too, 2017.), we do not find this particular analogy productive.">40</a></sup>the excess of environmental metaphors for data "do us a disservice by masking the human behaviors, relationships, and communications that make up all that data we're streaming and mining."<sup><a href="#footnote_40_2305" id="identifier_40_2305" class="footnote-link footnote-identifier-link" title="Hwang and Levy, “‘The Cloud’ and Other Dangerous Metaphors.”">41</a></sup>By analogizing digital data as a part of the "natural world"<span class="emdash">—</span>the latter term itself a techno-scientific reification and justification of centuries of imperial and settler colonial exploitation<sup><a href="#footnote_41_2305" id="identifier_41_2305" class="footnote-link footnote-identifier-link" title="Kavita Philip, “Nature, Culture Capital, Empire,” Capitalism Nature Socialism 18, no. 1 (March 2007): 5–12, doi:10.1080/10455750601164584.">42</a></sup><span class="emdash">—</span>the status of data as a record of human activity is doubly occluded.<sup><a href="#footnote_42_2305" id="identifier_42_2305" class="footnote-link footnote-identifier-link" title="Irina Raicu, “Metaphors of Big Data,” Recode, February 26, 2016.">43</a></sup></p>
<h1 style="text-align: center;">Method and Analysis</h1>
<p>To explore the relationships between data science, data metaphors, and professional ethics, we undertook a comparative discourse analysis of two sets of text-based data: 1) the text of ethics codes conventionally accepted as relevant to data science today and 2) the text of ethics codes from professions associated with popular or dominant data metaphors. Codes for both sets were accessed through the Center for the Study of Ethics in the Professions, which indexes more than 2500 codes and guidelines from over 1500 organizations, dating from 1887 to the present.<sup><a href="#footnote_43_2305" id="identifier_43_2305" class="footnote-link footnote-identifier-link" title="The CSEP’s Ethics Code Collection is available at http://ethicscodescollection.org. For further information on the CSEP’s collection and update policy, please see http://ethics.iit.edu/ecodes/node/5421.">44</a></sup> For our first set of codes, we drew from dominant professional associations in information and computing fields, namely the Association of Computing Machinery (ACM) and the Institute of Electrical and Electronics Engineers (IEEE). We also identified major professional associations in the areas of mathematics and statistics, like the American Statistical Association. This set of codes provide a baseline of historically salient professional and ethical concerns in domains which<span class="emdash">—</span>at least on the surface<span class="emdash">—</span>directly inform the development, training, and backgrounds of today's data scientists.<sup><a href="#footnote_44_2305" id="identifier_44_2305" class="footnote-link footnote-identifier-link" title="Jeff Hammerbacher, “Information Platforms and the Rise of the Data Scientist,” in Beautiful Data: the Stories Behind Elegant Data Solutions, ed. Toby Segaran and Jeff Hammerbacher, (Sebastopol, CA, 2009), 73–84.">45</a></sup></p>
<p>For the second set, we selected codes that 1) spoke directly to our identified metaphors/concepts and 2) were of sufficient length and substance to effectively compare with the well-developed codes in our first set. For example, if data is often framed as a natural resource, then we considered professions engaged in the extraction and stewardship of resources, as with forestry; if big data is considered "radioactive," then we looked to professionals tasked with the storage, management, and safekeeping of radioactive or toxic materials. Data collection was further informed by our own knowledge of terms and metaphors, derived from our own experiences working with and educating data scientists (for example, commonly employed terms like "cleaning,"<span class="emdash">—</span>i.e. processing<span class="emdash">—</span>data) and studying the ethics and rhetoric of data-intensive platforms more broadly.<sup><a href="#footnote_45_2305" id="identifier_45_2305" class="footnote-link footnote-identifier-link" title="Oliver L. Haimson and Anna Lauren Hoffmann, “Constructing and Enforcing ‘Authentic’ Identity Online: Facebook, Real Names, and Non-Normative Identities,” First Monday 21, no. 6 (June 6, 2016), doi: http://dx.doi.org/10.5210/fm.v21i6.6791; Anna Lauren Hoffmann, Nicholas Proferes, and Michael Zimmer, “‘Making the World More Open and Connected’: Mark Zuckerberg and the Discursive Construction of Facebook and Its Users,” New Media &amp; Society 12, no. 1 (January 13, 2017): 146144481666078–20, doi:10.1177/1461444816660784.">46</a></sup>We also drew on discussions of predictive analytics equating practices of data-driven forecasting and prediction with the work of astrologers.<sup><a href="#footnote_46_2305" id="identifier_46_2305" class="footnote-link footnote-identifier-link" title="Maude Standish, “Data Is the New Astrology,” The Huffington Post, April 25, 2013; Kate Crawford, “Asking the Oracle,” in Laura Poitras: Astro Noise, (New York/New Haven, CT, 2016), 138–53.">47</a></sup>Finally, inspired by descriptions of online data as the material traces humans leave behind (akin to, say, dead skin cells), we drew on the ethics of funeral directors and morticians charged with overseeing and caring for human remains.</p>
<p>In total, we selected 20 ethics codes for analysis. These codes ranged in length from approximately 330 to 4300 words, with a mean length of approximately 1300 words and a median length of approximately 800 words. Many of the codes were undated, with those with dates ranging from 1992 to 2016 (see Appendix A for details). We used the qualitative research software ATLAS.ti to aid in manual qualitative coding of the corpus according to principles of critical discourse analysis (CDA).<sup><a href="#footnote_47_2305" id="identifier_47_2305" class="footnote-link footnote-identifier-link" title="Theo van Leeuwen, Discourse and Practice: New Tools for Critical Discourse Analysis (Oxford Studies in Sociolinguistics), Oxford: Oxford University Press, 2008.">48</a></sup>We focused, in particular, on CDA's commitment to mark both the <em>social actors</em>and <em>social actions</em>explicit and implicit in a given text.<sup><a href="#footnote_48_2305" id="identifier_48_2305" class="footnote-link footnote-identifier-link" title="van Dijk, “Critical Discourse Analysis,” 466.">49</a></sup>As professional codes aim to regulate (to varying degrees) the practice of professionals in a given domain, we were interested first in identifying those actors (individual or institutional) and actions (encouraged or prohibited) conceived of as relevant by a given code. In addition, we also identified and labeled references to any explicit value or virtue (i.e., "fairness," "honesty," "integrity"), allowing us to connect specific values to specific actors or practices. As such, our analysis was "directed," as our coding scheme was derived both before (the actor/action frame adopted prior to coding) and during (values identified while coding) the analysis.<sup><a href="#footnote_49_2305" id="identifier_49_2305" class="footnote-link footnote-identifier-link" title="H. F. Hsieh, “Three Approaches to Qualitative Content Analysis,” Qualitative Health Research 15, no. 9 (November 1, 2005): 1277–88, doi:10.1177/1049732305276687.">50</a></sup></p>
<h1 style="text-align: center;">Analysis</h1>
<p>Despite the broad range of sampled fields and subject areas, ethics codes in the corpus demonstrated considerable thematic overlap. Much of this overlap is a matter of genre<span class="emdash">—</span>ethics codes are recognizable as such precisely because they share certain schematic and substantive markers.<sup><a href="#footnote_50_2305" id="identifier_50_2305" class="footnote-link footnote-identifier-link" title="Gaumnitz and Lere, “A Classification Scheme for Codes of Business Ethics.”">51</a></sup>For example, prohibitions on maintaining conflicts of interest were common across all codes, regardless of professional domain. In the following, we focus less on thematic overlap and instead on <em>social actors</em>and <em>social actions </em>explicit or implicit within the codes, noting 1) where the codes from different domains diverge and 2) and how each relates to representative virtues or other forms of ethical behavior.</p>
<h2 style="text-align: center;">Social Actors</h2>
<p>Professional ethics codes often position the individual practitioner as the primary locus of ethical responsibility.<sup><a href="#footnote_51_2305" id="identifier_51_2305" class="footnote-link footnote-identifier-link" title="Abbot, “Professional Ethics.”">52</a></sup>Individuals are asked to take the brunt of ethical conflict and adjudicate between potentially conflicting or incommensurate values.<sup><a href="#footnote_52_2305" id="identifier_52_2305" class="footnote-link footnote-identifier-link" title="Ethics codes thus perform for professionals in the abstract what the interaction design of many digital platforms does for gig workers in practice: figure their subjects as “moral liability sponges” or “moral crumple zones.” See Alex Rosenblat and Luke Stark, “Algorithmic Labor and Information Asymmetries: a Case Study of Uber’s Drivers,” The International Journal of Communication 10 (July 27, 2016): 3758–84; and M. C. Elish, “Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction” (We Robot 2016) (March 20, 2016). We Robot 2016 Working Paper. Available at SSRN: https://ssrn.com/abstract=2757236 or http://dx.doi.org/10.2139/ssrn.2757236 ">53</a></sup> The codes we examined followed this pattern, foregrounding the individual practitioner as a primary social actor through an emphasis on personal responsibility. Only rarely were codes extended to cover responsibilities of others, especially those above, around, or below an individual professional. References to individual professional competence also appear frequently across both sets of codes: individual professionals are directed to take on work or perform tasks only within their specific domain (or sub-domain) of expertise, and to not falsify or misrepresent their credentials.</p>
<p>What did vary, however, was the scope and range of social actors considered relevant to a professional context. The absence of considerations for third parties in most of the codes was notable, especially for professions where a code's stated professional ethical commitments could easily conflict with<span class="emdash">—</span>or had evident impacts on<span class="emdash">—</span>third parties. While a number of the sampled codes state commitments both to the general public and to the interests of the employer or profession more narrowly, the morality of a profession's or an employer's motives are not scrutinized, and the individual has no guidance on how to navigate moral conflicts. One exception was the Association of Computer Machinery's ethics code, which contained explicit provisions around whistleblowing<span class="emdash">—</span>likely inspired by the historical relationship between computing, state and corporate surveillance, and privacy harms.<sup><a href="#footnote_53_2305" id="identifier_53_2305" class="footnote-link footnote-identifier-link" title="David Lyon, ed., Surveillance as Social Sorting: Privacy, Risk and Digital Discrimination, (New York: Routledge, 2003); Herman Tavani, “Privacy Enhancing Technologies as a Panacea for Online Privacy Concerns: Some Ethical Considerations,” Journal of Information Ethics 9, no. 2 (2000); Helen Nissenbaum, “Respecting Context to Protect Privacy: Why Meaning Matters,” Science and Engineering Ethics 109, no. 4 (July 11, 2015): 1–22, doi:10.1007/s11948-015-9674-9.">54</a></sup></p>
<p>Other actors<span class="emdash">—</span>sometimes people, other times objects, spaces, or ideals<span class="emdash">—</span>are evoked across these codes through what we refer to as "responsibility to" language. At any given time, an individual professional may have (per their relevant code) a responsibility to: specific other actors (clients, colleagues, users, employees, or employers); general others (the public, society, or simply "others"); a political body (nation, country); specific objects or ideals (technology, truth, knowledge, the profession); or abstract spaces or sites (nature). The particular discursive arrangement of these other actors hints at a given code's imagined scope. Those addressing only interpersonal or work relationships with colleagues, employers, or employees could be understood as relatively narrow in scope, suggesting the body responsible for developing the code either 1) did not imagine the profession as playing a broad social role or 2) wanted to actively avoid offering moral guidance on issues beyond the immediate workplace.</p>
<p>Beyond colleagues and employer/employee relationships, some of the surveyed codes cited specific responsibilities to users (presumably of a particular system and not of technology generally). This focus was, unsurprisingly, a common theme in computing and information codes, where broader ethical commitments were often treated as high-level abstractions and more precise attention was paid to intra-professional considerations. Accordingly, social issues and problems of the public good were often reduced to their most technocratic features. For example, the Code of Ethics of the American Society for Information Society &amp; Technology (ASIS&amp;T) begins by urging "its members to be ever aware of the social, economic, cultural, and political impacts of their actions or inaction," yet proceeds to detail explicit responsibilities to employers, clients, and system users<span class="emdash">—</span>and not society more broadly.</p>
<p>Other information and computing codes also evoked such "general others" briefly. The IEEE Code of Ethics merely implores professionals "to accept responsibility in making decisions consistent with the safety, health, and welfare of the public, and to disclose promptly factors that might endanger the public or the environment." The Association of Computing Machinery (ACM) was again an exception, with its code going into detail regarding "general moral imperatives" and their specific features. For example, the broad stated obligation to "contribute to society and human well-being" is followed by the somewhat more precise imperative to "protect fundamental human rights" and "respect the diversity of all cultures." While still vague, this explication does offer some insight into how the ACM conceives of "human well-being."</p>
<p>In contrast to information and computing codes, codes related to statistics and statistical work consistently foregrounded professional responsibilities to the public or society. The Statistical Society of Canada lists responsibilities to society first while the Royal Statistical Society (UK) singles out "an overriding responsibility to the public good." The American Statistical Association (ASA) goes the furthest in making statisticians' responsibility towards society explicit, averring that "the discipline of statistics links the capacity to observe with the ability to gather evidence and make decisions, providing a foundation for building a more informed society." The ASA also details a set of commitments aiming to limit or reduce the chance an individual practitioner will be placed in a morally tenuous position by a third party, for example by "[striving] to protect the professional freedom and responsibility of statistical practitioners," especially in cases where "analyses...are known or anticipated to have tangible physical, financial, or psychological impacts." Further, it asks employers to "recognize that the results of valid statistical studies cannot be guaranteed to conform to the expectations or desires of those commissioning the study or the statistical practitioner(s)." While the ASA code does not stipulate further ethical commitments the employer may have, it does to some degree acknowledge and incorporate the how statistical work interacts with corporate or other institutional processes.</p>
<p>In addition, these statistics-based ethics codes incorporate ethical concerns from the broader history and trajectory of research ethics. The ASA code specifically details an obligation to seek consent, especially for secondary or indirect uses of data. It also gestures towards concerns of justice in research ethics, noting, "statistical descriptions of groups may carry risks of stereotypes and stigmatization." In response, "statisticians should contemplate, and be sensitive to, the manner in which information is framed so as to avoid disproportionate harms to vulnerable groups." Given these codes are intended to inform statisticians' research practices, it is perhaps unsurprising the treatment of research subjects would feature prominently as objects of ethical concern - but makes it all the more notable that data scientists, who as Beaton notes share a lineage with both statisticians and psychologists, have yet to fully embrace such language.<sup><a href="#footnote_54_2305" id="identifier_54_2305" class="footnote-link footnote-identifier-link" title="Brian Beaton, “How to Respond to Data Science: Early Data Criticism by Lionel Trilling,” Information &amp; Culture: a Journal of History 51, no. 3 (August 2016): 352–72. doi:10.7560/IC51303.">55</a></sup></p>
<p>Codes associated with data metaphors often suggested responsibility to broadly construed spaces, sites, or ideals through the language of stewardship. For instance, the Society of American Foresters defines the forestry profession as "[serving] society by fostering stewardship of the world's forests," while the North American Nature Photography Association articulates its ethics through principles of stewardship of and non-interference with various natural habitats. Professions charged with sanitation, cleanliness, or dealing with hazardous waste also address environmental concerns. For Certified Hazardous Materials Managers, the "primary responsibility is to protect the public and the environment." For the International Sanitary Supply Association (ISSA), public health is paramount<span class="emdash">—</span>all commercial considerations are, according to their code of ethics, secondary to this broader concern.</p>
<p>In contrast to stewardship-based or environmental models, which tend to refer to objects in the material world, computing and statistics codes tend to foreground a specific value or ideal and then work to situate professional ethical responsibilities in service of this higher ideal. In statistics codes, for example, "truth" and "objective knowledge" emerge as both quasi-deontological ends-in-themselves and contested categories professionals must strive to realize in their work. Section A of the American Statistical Association specifically addresses statisticians' obligations to reduce, mitigate against, or eliminate biases<span class="emdash">—</span>either on the part of the professional or the contracting party<span class="emdash">—</span>which might skew research results. An ethical statistician, the Code asserts, "uses methodology and data that are relevant and appropriate, without favoritism or prejudice, and in a manner intended to produce valid, interpretable, and reproducible results." The unethical statistician, then, is one who manipulates data or skews findings in ways that are self-serving or aims to deliberately mislead or manipulate others.</p>
<p>Finally, there was also variation in the codes with regard to the positioning of ethics relative to a given professional. In a few cases, ethics was construed not as a set of commitments, but as constitutive of professional identity. For example, the code of ethics for the Association of Information Technology Professionals (AITP) states the standards set out by the code "are not objectives to be strived for, they are rules that no true professional will violate." Though seemingly minor, this difference has consequences for professional identity and regulation: ethics as professional commitment implies one can remain a "professional" even when acting in ways potentially construed as unethical, while, conversely, ethics as constitutive of professional identity implies that a breach of ethics simultaneously disqualifies one's status as a professional.</p>
<h2 style="text-align: center;">Values and Social Actions</h2>
<p>Where the previous section focused on actors and objects, this section focuses on specific values and actions captured or implied in the surveyed ethics codes. Not only do ethics codes represent an effort to define and delimit an ideal ethical professional, they also work to articulate, set, and scope out the sorts of actions and values endemic to a particular profession. These actions often perform justificatory work (e.g., positioning certain actions as socially useful helps justify a profession's existence) or work to stave off certain types of attention (e.g., clearly stated prohibitions on certain actions may help deflect public or regulatory scrutiny). Additionally, stated values reveal something about the anticipated impact of a given action<span class="emdash">—</span>positioning something as potentially discriminatory, for example, demonstrates an awareness of a profession's political impact. In this way, references to specific values or virtues offer insight into the ethical tenor of actions an individual might be expected to undertake or account for in their capacity as a professional.</p>
<p>Within the inventory of values laid out in the codes we analyzed, some of the starkest divisions came between computing and statistics codes, and those codes associated with data metaphors. A dominant theme across all analyzed codes was a proscription against what we term "biopolitical harms": environmental harms, and the health and safety of populations.<sup><a href="#footnote_55_2305" id="identifier_55_2305" class="footnote-link footnote-identifier-link" title="Patricia Ticineto Clough and Craig Willse, “Gendered Security/National Security: Political Branding and Population Racism,” March 7, 2013; Michel Foucault Collège de France, The Birth of Biopolitics: Lectures at the Collège De France, 1978-1979, 1st ed., (New York: Picador, 2010); Matthew B Sparke, “A Neoliberal Nexus: Economy, Security and the Biopolitics of Citizenship on the Border,” Political Geography no. 25, no. 25 (2006): 151–80, doi:10.1016/j.polgeo.2005.10.002.">56</a></sup>This emphasis suggests a parallel to the preponderance of resource-based metaphors for data<span class="emdash">—</span>namely a sense that, in the abstract, it is easy for professionals to agree to protecting (or perhaps, managing) the natural world and natural resources, as part of what Gabriel Abend terms "the moral background" to professionalism itself.<sup><a href="#footnote_56_2305" id="identifier_56_2305" class="footnote-link footnote-identifier-link" title="Gabriel Abend, The Moral Background (Princeton, NJ and Oxford: Princeton University Press, 2014).">57</a></sup>In contrast, computing codes and statistics codes often foreground political issues of privacy and freedom of speech, as well as conceptions of data as confidential and requiring safeguarding. This attention to privacy, security, and speech grows out of a longer-standing focus on these areas during the development of information technology and computing ethics.<sup><a href="#footnote_57_2305" id="identifier_57_2305" class="footnote-link footnote-identifier-link" title="Tavani, “The State of Computer Ethics as a Philosophical Field of Inquiry;” Frances S. Grodzinsky and Herman T. Tavani, “Applying the ‘Contextual Integrity’ Model of Privacy to Personal Blogs in the Blogosphere,” International Journal of Internet Research Ethics 3 (December 30, 2010): 38–47; Lucas D. Introna, “Maintaining the Reversibility of Foldings: Making the Ethics (Politics) of Information Technology Visible,” Ethics and Information Technology 9, no. 1 (December 21, 2006): 11–25, doi:10.1007/s10676-006-9133-z.">58</a></sup>Save for limited references to confidentiality in the codes of The Wildlife Society and Society of American Foresters, privacy and speech considerations are absent in our second set of codes.</p>
<p>Given established historical connections between information technology, communication, and privacy, the emphasis on the latter in computer science codes makes sense. However, it also points to one of the starkest differences between the conventional codes and those codes rooted in our data metaphors: the former tends to foreground abstract users, rights, and values, while many of the metaphor-based codes explicitly revolve around material stewardship, public health, and bodily safety. For example, the Code of Ethics for Hazardous Materials Managers explicitly states that professionals' "primary responsibility is to protect the public and the environment," while "the interests of individual clients and employers must be secondary." In a different way, the code of ethics for The Wildlife Society places "research and scientific management of wildlife species, their environments, and stakeholders" as primary and specifically directs professionals to educate broadly construed others on these topics. This contrast between abstract values in the conventional codes and material stewardship in the metaphor-based codes lends support to the idea that conventional codes' outsized focus on issues like privacy and speech<span class="emdash">—</span>themselves heavily informed by the technical rather than social affordances of computers<span class="emdash">—</span>has limited their ability to account for a wider range of potential social, political, and environmental harms.<sup><a href="#footnote_58_2305" id="identifier_58_2305" class="footnote-link footnote-identifier-link" title="Literature on the concept of “securitization” supports this view: when topics of public debate are securitized, they are removed from the realm of political contestation and deemed to be technical matters addressable by experts. See Lene Hansen and Helen Nissenbaum, “Digital Disaster, Cyber Security, and the Copenhagen School,” International Studies Quarterly 53 (2009): 1155–75; Helen Nissenbaum, “Where Computer Security Meets National Security,” Ethics and Information Technology 7 (2005): 61–73, doi:10.1007/s10676-005-4582-3.">59</a></sup>A focus on natural resources as a site for both conservation and potential harm also helps professionals avoid the social complexities and challenges of adjudicating their responsibilities to society as comprised of other people, instead of a material background.</p>
<p>Finally, a number of the sampled codes formally prohibit discrimination, and some others contain explicit lists of those classes of people deserving of particular protection. However, only the code of ethics for the National Funeral Directors Association made an explicit connection between the mission of the profession and a specific vulnerable class of people.<sup><a href="#footnote_59_2305" id="identifier_59_2305" class="footnote-link footnote-identifier-link" title="It is worth noting that The Wildlife Society does address unspecified “stakeholders” in the well-being of certain wildlife species. These stakeholders could easily include oppressed individuals or groups deserving of particular consideration, especially native or indigenous peoples. However, these groups are not specifically named in the code.">60</a></sup> Specifically, people of low socioeconomic standing or limited financial means are cited as deserving particular consideration in view of funeral directors' mission to "to provide families with meaningful end-of-life services at the highest levels of excellence and integrity."<sup><a href="#footnote_60_2305" id="identifier_60_2305" class="footnote-link footnote-identifier-link" title="“About NFDA,” National Funeral Directors Association, June 9, 2018.">61</a></sup>This commitment is explicitly accounted for in a prohibition against withholding services (like delaying the embalming process) or the body of a loved one (from release to a family or other legally recognized party) until payment for services has been received. While clearly rooted in a concern over extortionate business practices and hucksterism<span class="emdash">—</span>as well as the time sensitive nature of some features of morticians' work<span class="emdash">—</span>there is, perhaps a lesson for data scientists here in how to think about specific power dynamics at play. For example, a code of ethics for data scientists might be careful to not make certain kinds of data or informational transparency contingent on an ability to pay or by coercing users to give up more personal data in the process.</p>
<h1 style="text-align: center;">Discussion &amp; Recommendations</h1>
<p>Our analyses of professional ethics codes from both computer science and from metaphorically related fields suggest several broad conclusions relevant to conversations about data in the public sphere, and to data science as an emerging profession.</p>
<p>First, one of the chief values common to codes from across our sample was fairness. In the context of computer science ethics, fairness is a hot topic: computer scientists interested in fairness, accountability, transparency and other values in machine learning and artificial intelligence have already begun to interrogate how fairness might be translated into computational metrics for evaluating algorithms and systems.<sup><a href="#footnote_61_2305" id="identifier_61_2305" class="footnote-link footnote-identifier-link" title="Solon Barocas and Andrew D. Selbst, “Big Data’s Disparate Impact,” California Law Review 104 (2016): 671–732. doi:10.15779/Z38BG31; Chelsea Barabas, Madars Virza, Karthik Dinakar, Joichi Ito, and Jonathan Zittrain, “Interventions Over Predictions - Reframing the Ethical Debate for Actuarial Risk Assessment,” Proceedings of Machine Learning Research 81:1-15, 2018.">62</a></sup>A parallel movement in science and technology studies and information science has focused on the need to articulate fairness not only as an allocative metric internal to digital systems, but also as social one addressing systematic discrimination, bias, and representational harms.<sup><a href="#footnote_62_2305" id="identifier_62_2305" class="footnote-link footnote-identifier-link" title="Anna Lauren Hoffmann, “Data Violence and How Bad Engineering Choices Can Damage Society,” Medium (Member Feature Story), 30 April 2018, available at https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4">63</a></sup>In the context of professional ethics codes, however, fairness takes on yet another meaning: as a sign of interpersonal trust within a profession, and a signal for professional frankness and honesty.</p>
<p>The strong emphasis on fairness within the conventional codes we sampled may in fact be connected to the technical definitions of fairness increasingly prominent in computer science literature: technical systems are perceived by computer scientists and data scientists as objects which are the fruit of expert processes of collaboration and communication, and so those same expert processes would, in theory, be able to similarly produce technical definitions of values<span class="emdash">—</span>such as fairness. The strong emphasis on computational solutions to values questions has much to do with common areas of professional familiarity, expertise and technical language among participants. Fairness is a complicated concept in non-computational contexts as well as computational ones. We argue, however, a reemphasis on fairness as a social value (in line with honesty, frankness, and "good faith") would help reorient data science and related professions towards their broader social role.</p>
<p>The professional codes we sampled<span class="emdash">—</span>from CS and from other fields<span class="emdash">—</span>are also highly focused on technical and professional credibility. This second insight is related to our first point above: professional fairness and honesty are integral to technical credibility and recognition of expertise. However, scholarly work in the sociology of trust that observes trust as a social construct is only partially focused on technical credibility, or whether a person or institution is able to perform the task they claim they will do.<sup><a href="#footnote_63_2305" id="identifier_63_2305" class="footnote-link footnote-identifier-link" title="Linda D. Molm, Nobuyuki Takahashi, and Gretchen Peterson, “Risk and Trust in Social Exchange: an Experimental Test of a Classical Proposition,” The American Journal of Sociology 105, no. 5 (March 2000): 1396–1427; Susan P. Shapiro, “The Social Control of Impersonal Trust,” American Journal of Sociology 93, no. 3 (November 1987): 623–58; Guido Möllering, “The Trust/Control Duality,” International Sociology 20, no. 3 (June 29, 2016): 283–305, doi:10.1177/0268580905055478.">64</a></sup>While the voluminous literature on trust is too broad to more than briefly sample here, the other key aspect of social trust is benevolence: the notion that a trusted person or organization has the best interests of the trustor at heart.<sup><a href="#footnote_64_2305" id="identifier_64_2305" class="footnote-link footnote-identifier-link" title="Matthew K. O. Lee and Efraim Turban, “A Trust Model for Consumer Internet Shopping,” International Journal of Electronic Commerce 6, no. 1 (October 1, 2001): 75–91, doi:10.2307/27751003?ref=search-gateway:65426dfa915042907ae6237cf88297e1; David Gefen, Izak Benbasat, and Paula Pavlou, “A Research Agenda for Trust in Online Environments,” Journal of Management Information Systems 24, no. 4 (May 12, 2008): 275–86, doi:10.2753/MIS0742-1222240411.">65</a></sup>The emphasis across professional codes for computer science is credibility, and less so benevolence.</p>
<p>Given an increasing scholarly and public awareness of the social impacts of big data, ML, and AI, the lack of attention to social benevolence in the conventional codes is notable and in need of remedy. Here, insights rooted in our data metaphors stand to be of particular use. For certain professions concerned with, for example, sanitation or the handling of hazardous materials, benevolence (often in the form public or environmental safety) is paramount<span class="emdash">—</span>it works as an overarching frame for judgments of professional duty and competence. Accordingly, we should ask critical questions about how broadly or narrowly "competence" in particular data scientific projects should be construed. For example, while a data scientist might have expertise in particular computational and statistical methods, they may know very little<span class="emdash">—</span>in the social scientific sense<span class="emdash">—</span>about the particular communities or behaviors captured in a given dataset. Interpreting competence in view of social benevolence would require some knowledge of particular communities, behaviors, or broader social and political forces (or at least a requirement to contract or seek out collaborations with other professionals or community members who do possess such expertise). In certain contexts, it may even be useful to follow the lead of morticians and funeral directors in codifying historically-salient social or political groups deserving of particular consideration. Though not represented in our surveyed codes, the activist slogan "nothing about us without us" (notably espoused by disability activists in the United States) may be a useful starting point for reasoning about data scientists' social obligations.<sup><a href="#footnote_65_2305" id="identifier_65_2305" class="footnote-link footnote-identifier-link" title="James I. Charlton, Nothing About Us Without Us: Disability Oppression and Empowerment, (Berkeley and Los Angeles: University of California Press, 1998).">66</a></sup></p>
<p>In addition, ethical commitments addressing both the employer and the employed, as well as possible conflicts between those ethical commitments, are particularly relevant for thinking through the ethics of data science within large corporate settings. Economic incentives and ethical commitments to the privacy, security and labor rights of both data subjects and employees often come into conflict<sup><a href="#footnote_66_2305" id="identifier_66_2305" class="footnote-link footnote-identifier-link" title="Noëmi Manders-Huits and Michael Zimmer, “Values and Pragmatic Action: The Challenges of Introducing Ethical Intelligence in Technical Design Communities,” International Review of Information Ethics, January 30, 2009, 1–8.">67</a></sup><span class="emdash">—</span>for example, when data or scientific work might contribute to the development of military weapons and targeting systems. How to harmonize broad social commitments with both individual professional practice and corporate structures in the data science context<span class="emdash">—</span>especially since, given the heavy reliance on gig or crowd labor in data science, it remains an open question just who the individual professional figured across the codes we surveyed might be<span class="emdash">—</span>is a necessary subject for further research and activism.<sup><a href="#footnote_67_2305" id="identifier_67_2305" class="footnote-link footnote-identifier-link" title="Kate Conger, “Google Plans Not to Renew Its Contract for Project Maven, a Controversial Pentagon Drone AI Imaging Program,” Gizmodo, June 1, 2018.">68</a></sup>Related conversations around the ethics and governance of AI provide an instructive parallel case.<sup><a href="#footnote_68_2305" id="identifier_68_2305" class="footnote-link footnote-identifier-link" title="Daniel Greene, Anna Lauren Hoffmann, and Luke Stark, “Better, Nicer, Clearer, Fairer: A Critical Assessment of the Movement for Ethical Artificial Intelligence and Machine Learning,” Hawaii International Conference on System Sciences (HICSS 2019), Maui, HI.">69</a></sup> Data governance through the lens of human rights is one possible approach in this vein, though the suitability and effectiveness of human rights discourse in mobilizing good corporate governance and change for social justice is an open question.<sup><a href="#footnote_69_2305" id="identifier_69_2305" class="footnote-link footnote-identifier-link" title="Mark Latonero, Governing Artificial Intelligence: Upholding Human Rights and Dignity, Data &amp; Society Research Institute, (10 October 2018), available at https://datasociety.net/output/governing-artificial-intelligence/; Ron Dudai, “Human Rights in the Populist Era: Mourn then (Re)Organize,” Journal of Human Rights Practice 9, no. 1 (February 2017): 16–21. https://doi.org/10.1093/jhuman/hux005">70</a></sup></p>
<p>A related insight drawn from our analysis concerns the notion of the fiduciary, and their "fiduciary duty." A fiduciary is a trustee, and a fiduciary duty is the legal obligation of one party to act in the best interest of another. Doctors and lawyers, for instance, have fiduciary duties to their patients and clients<span class="emdash">—</span>so do other professionals such wealth managers and morticians. Legal scholars Jack Balkin and Jonathan Zittrain have recently developed the concept of the "information fiduciary,"<sup><a href="#footnote_70_2305" id="identifier_70_2305" class="footnote-link footnote-identifier-link" title="Jack M. Balkin, “Information Fiduciaries and the First Amendment,” UC Davis Law Review 49, no. 4 (April 2016): 1183–1234.">71</a></sup>entailing data scientists and the companies they work for<span class="emdash">—</span>like Facebook and Google<span class="emdash">—</span>accepting "the duty to use personal data in ways that don't betray end users and harm them."<sup><a href="#footnote_71_2305" id="identifier_71_2305" class="footnote-link footnote-identifier-link" title="Jack M. Balkin and Jonathan Zittrain, “A Grand Bargain to Make Tech Companies Trustworthy,” The Atlantic, October 3, 2016.">72</a></sup></p>
<p>We see several points from our analysis pertaining to the information fiduciary model. One is that for the most part, professions with fiduciary duties protect personal data as a secondary result of their primary duty of care: to the health of a patient, to (in theory) the law and justice, to the bodies of the dead. For example, doctors and morticians, more so than lawyers, are intimately engaged in caring for us as embodied agents. Standards for trusting doctors and morticians are thus high: we imagine a doctor, on the average, to be honest<span class="emdash">—</span>both credible and benevolent<span class="emdash">—</span>in a way we may not (alas) imagine a computer scientist.</p>
<p>Data scientists and their employers are generally presented as being in the business of collecting and analyzing data as a primary goal<span class="emdash">—</span>but this is of course an erroneous view. Data scientists and computer programmers invariably work in and across various domains and their work has, in many cases, obvious material consequences<span class="emdash">—</span>from precision medicine to criminal sentencing.Here, the emphasis on material stewardship found in metaphor-based codes of ethics, as opposed to the valorization of abstract ideals found in many computer science codes, shows how the material objects of a profession's attention can be obscured by a profession's conceptual axioms. Data scientists as a profession are generally associated with abstraction and disembodiment, with numbers aggregated and immaterial in "the cloud." Yet the real-world consequences on individual embodied humans of data science can be real, visceral, and devastating. Likewise, discourses of data as a force, a resource, and as an industrial product erase the human subjects both of digital data collection and accumulation and its effects; yet they also lack the traditions of stewardship and responsibility, which however imperfectly typify the professional discourses in those fields.</p>
<p>Analogizing digital data as "natural" without stewardship discourses implicitly signals data - and the living people it involves - are open for rank exploitation. As Arvind Narayanan argues, "it's not enough to ask if code executes correctly. We also need to ask if it makes society better or worse."<sup><a href="#footnote_72_2305" id="identifier_72_2305" class="footnote-link footnote-identifier-link" title="Doug Hulette, “Patrolling the Intersection of Computers and People,” Princeton University Computer Science, October 2, 2017.">73</a></sup>The seeming abstraction of data is in some ways belied by the material metaphors used to describe it: water, oil, and ore. Yet as Hwang and Levy note, these metaphors, though material, deflect attention from the fact human data are produced and have impacts on human beings. We heartily concur with Rebecca Lemov: "'Big data is people'!"<sup><a href="#footnote_73_2305" id="identifier_73_2305" class="footnote-link footnote-identifier-link" title="Rebecca Lemov, “‘Big data is people!’” Aeon Magazine, June 16, 2016.">74</a></sup>As such, we argue data scientists should be held to fiduciary standards closer to those of doctors, morticians, or even hazardous waste managers<span class="emdash">—</span>they are professionals dealing with the human bodies and populations in ways that demand a high degree of both credibility and benevolence. Professional ethics in data science should include broader, more ecological thinking about the role of data, computing, and statistical analyses in their social context and real-world applications.</p>
<p>One final area where professional ethics codes related to data metaphors differed from those in computer science was around the question of professional sanction. For instance, the ethical code of the International Society of Petroleum Engineers has an explicit clause encouraging practical mitigating action, and also states in the code itself the mechanism through which members can report violations to the professional body. If data is indeed the new oil, the IEEE and other data science codes should be at least as explicit as that of petroleum engineers in listing consequences for violations of the code and articulating how those violations can be reported.</p>
<p>As noted above, there is one professional group thematically related to data science whose professional ethics codes demonstrate a relatively high degree of sensitivity to a variety of actors, societal values and broad-based social responsibility: statisticians. Given the centrality of statistical analysis to data science, we suggest data scientists could do much worse than having a full-throated professional engagement with statistical codes of conduct, and with the legacy of statistics as a tool in social science research. Like data scientists, statisticians work with many other professions, but nonetheless have articulated their social obligations. Future scholarship engaging statisticians around the concept of "fiduciary duty" would be valuable<span class="emdash">—</span>a statistical fiduciary duty of care is one conceptual way to understand the professional duties of data scientists and others engaging in data analysis.</p>
<h1 style="text-align: center;">Conclusion</h1>
<p>Our analytic goals in juxtaposing ethics codes in computer science and related fields alongside codes related to data science metaphors are threefold. As scholars working at the intersection of information science, science and technology studies (STS), and the philosophy and ethics of technology, we have an intellectual interest in tracing the conceptual connections and sociological themes of computer and data science, the professions which to a large degree shape the technologies and social practices around them which we study.  Ethics codes are a micro-level instantiation of broader structural and institutional values and debates. These codes represent "the transformation of social practices into discourses about social practices";<sup><a href="#footnote_74_2305" id="identifier_74_2305" class="footnote-link footnote-identifier-link" title="Theo van Leeuwen, Discourse and Practice: New Tools for Critical Discourse Analysis (Oxford Studies in Sociolinguistics), Oxford: Oxford University Press, 2008, 105.">75</a></sup>they are not absolute or perfect representations of these discussions but sites where certain results of certain political, professional, and material struggles are stabilized and put to work in the world.</p>
<p>However, we are also concerned with two other, practical normative outcomes: a statement of the kinds of ethos we as critical scholars want to see permeate these emerging data cultures; and a concomitant sense of how data scientists might consider changing existing or nascent professional ethics codes in data science in light of our findings and our broader normative commitments.</p>
<p>While many of our proposals are spelled out in the Discussion section above, we make two more general recommendations for data scientists and those interested in professional ethics for data science. The first recommendation is to take "ethics" as a starting point, not as an end. Codes of ethics increasingly serve to demarcate data culture as a domain of experts, and conversations around professional ethics in data science and related fields such as ML/AI are a necessary but absolutely insufficient condition for the kinds of progressive, just and equitable social outcomes we seek for the world. Testifying before the US Congress in 2003 about another new and disruptive technical field, nanotechnology, STS scholar Langdon Winner noted a historical tendency, as he saw it, "for those who conduct research about the ethical dimensions of emerging technology to gravitate toward the more comfortable, even trivial questions involved, avoiding issues that might become a focus of conflict."<sup><a href="#footnote_75_2305" id="identifier_75_2305" class="footnote-link footnote-identifier-link" title="Langdon Winner, Testimony to the Committee on Science of the U.S. House of Representatives on The Societal Implications of Nanotechnology, 9 April 2003, available at http://homepages.rpi.edu/~winner/testimony.htm.">76</a></sup> Digital technologies are powerful tools: for data scientists to insufficiently engage with the rich social contexts and disparate, sometimes conflicting human realities of their use is a lapse of a core ethical obligation, courage, in itself. To limit conversations about the societal impacts and obligations of data science solely to professional ethics is a mistake we are keen to have all parties involved avoid.</p>
<p>Our second recommendation concerns the relationship between professional ethics codes in data science and data science pedagogy. The ethical norms of a profession emerge out of every stage of that profession's training process. As such, we advocate forcefully for data science education to address not only the professional ethics questions posed by extant professional codes, but also the societal questions posed by the metaphors through which the profession, and discourse more broadly, understands data. These metaphors can serve as what Katie Shilton<sup><a href="#footnote_76_2305" id="identifier_76_2305" class="footnote-link footnote-identifier-link" title="Katie Shilton,“Values Levers: Building Ethics Into Design,” Science, Technology, &amp; Human Values 38, no. 3 (May 2013): 374–97, doi:10.1177/0162243912436985.">77</a></sup>terms "values levers," prompting novel conversations about data science's impacts and responsibilities to society at large. Innovative work on broadening the terms of data science education is already underway.<sup><a href="#footnote_77_2305" id="identifier_77_2305" class="footnote-link footnote-identifier-link" title="Michael Skirpan et al., “Ethics Education in Context,” (the 49th ACM Technical Symposium, New York, New York, USA: ACM Press, 2018), 940–45, doi:10.1145/3159450.3159573; [Author, 2018]; Costanza-Chock, “Design Justice: Towards an Intersectional Feminist Framework for Design Theory and Practice.”">78</a></sup>Data science and data scientists would benefit from expanding their collaborations with interdisciplinary work in STS, information studies, and media studies to further reap the benefits of engaging with values, ethics, and norms at every stage of their work.<sup><a href="#footnote_78_2305" id="identifier_78_2305" class="footnote-link footnote-identifier-link" title="Mary Flanagan and Helen Nissenbaum, Values at Play in Digital Games, (Cambridge, MA: The MIT Press, 2014); Phoebe Sengers et al., “Reflective Design,” (Proceedings of the 4th Decennial Aarhus Conference, Aarhus, Denmark, 2005), 49–58; Batya Friedman, Peter H. Kahn, and Alan Borning, “Value Sensitive Design and Information Systems,” in Human-Computer Interaction in Management Information Systems: Foundations, ed. B. Schneiderman, Ping Zhang, and D. Galletta, (New York: M.E. Sharpe, Inc., 2006), 348–72.">79</a></sup></p>
<p>Finally, our ethical commitments as authors are grounded in a desire for data justice,<sup><a href="#footnote_79_2305" id="identifier_79_2305" class="footnote-link footnote-identifier-link" title="Hoffmann, “Data Violence.”">80</a></sup>design justice,<sup><a href="#footnote_80_2305" id="identifier_80_2305" class="footnote-link footnote-identifier-link" title="Sasha Costanza-Chock, “Design Justice: Towards an Intersectional Feminist Framework for Design Theory and Practice,” 2018, 1–14, doi:10.21606/dma.2017.679.">81</a></sup>as well as the recognition of historical injustices in emerging data cultures and in society more broadly. As Kate Crawford has put it, data ethics needs to ask, "What kind of world do we want to live in?"<sup><a href="#footnote_81_2305" id="identifier_81_2305" class="footnote-link footnote-identifier-link" title="Kate Crawford, “AI Now: Social and Political Questions for Artificial Intelligence,” (University of Washington, March 6, 2018), available at: https://www.youtube.com/watch?v=a2IT7gWBfaE.">82</a></sup>We are explicit about these normative commitments as a way to conceptually tax related ethics codes and our data metaphors alike. With data-driven online platforms and digital systems already a potential source of bias and discrimination,<sup><a href="#footnote_82_2305" id="identifier_82_2305" class="footnote-link footnote-identifier-link" title="Batya Friedman and Helen Nissenbaum, “Bias in Computer Systems,” ACM Transactions on Information Systems 14, no. 3 (September 5, 1996): 330–47; Joy Buolamwini and Timnit Gebru, “Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,” Proceedings of Machine Learning Research 81 (2018): 1–15.">83</a></sup>the processual ethics common to professional codes need to be supplanted by a more explicit set of norms around data cultures as spaces for equality and justice<span class="emdash">—</span>within and beyond a code of ethics for data scientists.</p>
<h2></h2>
<h2>Appendix: List of Professional Ethics Codes Consulted</h2>

<table id="tablepress-94-no-2" class="tablepress tablepress-id-94">
<thead>
<tr class="row-1 odd">
	<th class="column-1">Organization</th><th class="column-2">Date Last Updated</th><th class="column-3">Word Count</th>
</tr>
</thead>
<tbody class="row-hover">
<tr class="row-2 even">
	<td class="column-1">American Federation of Astrologers (AFA) Code of Ethics</td><td class="column-2">No date listed</td><td class="column-3">356</td>
</tr>
<tr class="row-3 odd">
	<td class="column-1">American Mathematical Society Policy Statement on Ethical Guidelines</td><td class="column-2">2005</td><td class="column-3">1729</td>
</tr>
<tr class="row-4 even">
	<td class="column-1">American Society for Photogrammetry and Remote Sensing Code of Ethics</td><td class="column-2">No date listed</td><td class="column-3">658</td>
</tr>
<tr class="row-5 odd">
	<td class="column-1">American Statistical Association (ASA) Ethical Guidelines for Statistical Practice</td><td class="column-2">2016</td><td class="column-3">3478</td>
</tr>
<tr class="row-6 even">
	<td class="column-1">Association for Computing Machinery (ACM) Code of Ethics and Professional Conduct</td><td class="column-2">1992</td><td class="column-3">3459</td>
</tr>
<tr class="row-7 odd">
	<td class="column-1">Association for Information Science and Technology (ASIS&amp;T) Professional Guidelines</td><td class="column-2">1992</td><td class="column-3">531</td>
</tr>
<tr class="row-8 even">
	<td class="column-1">Association for Information Systems (AIS) Code of Research Conduct</td><td class="column-2">2013</td><td class="column-3">4323</td>
</tr>
<tr class="row-9 odd">
	<td class="column-1">Association of Information Technology Professionals (AITP) Code of Ethics &amp; Standards of Conduct</td><td class="column-2">No date listed</td><td class="column-3">790</td>
</tr>
<tr class="row-10 even">
	<td class="column-1">Information Systems Security Association (ISSA) Code of Ethics</td><td class="column-2">No date listed</td><td class="column-3">332</td>
</tr>
<tr class="row-11 odd">
	<td class="column-1">Institute for Certification of Computing Professionals (ICCP) Code of Ethics</td><td class="column-2">No date listed</td><td class="column-3">2145</td>
</tr>
<tr class="row-12 even">
	<td class="column-1">Institute of Electrical and Electronics Engineers (IEEE) Code of Ethics</td><td class="column-2">No date listed</td><td class="column-3">429</td>
</tr>
<tr class="row-13 odd">
	<td class="column-1">Institute of Hazardous Materials Management Code of Ethics and Professional Conduct</td><td class="column-2">No date listed</td><td class="column-3">895</td>
</tr>
<tr class="row-14 even">
	<td class="column-1">International Society of Petroleum Engineers Code of Ethics</td><td class="column-2">2013</td><td class="column-3">561</td>
</tr>
<tr class="row-15 odd">
	<td class="column-1">National Funeral Directors Association Code of Professional Conduct</td><td class="column-2">2008</td><td class="column-3">1530</td>
</tr>
<tr class="row-16 even">
	<td class="column-1">North American Nature Photography Association</td><td class="column-2">No date listed</td><td class="column-3">465</td>
</tr>
<tr class="row-17 odd">
	<td class="column-1">Royal Statistical Society</td><td class="column-2">No date listed</td><td class="column-3">1718</td>
</tr>
<tr class="row-18 even">
	<td class="column-1">Society of American Foresters Code of Ethics</td><td class="column-2">2000</td><td class="column-3">833</td>
</tr>
<tr class="row-19 odd">
	<td class="column-1">Statistical Society of Canada Code of Ethical Statistical Practice</td><td class="column-2">No date listed</td><td class="column-3">766</td>
</tr>
<tr class="row-20 even">
	<td class="column-1">The Wildlfe Society Code of Ethics</td><td class="column-2">No date listed</td><td class="column-3">1486</td>
</tr>
<tr class="row-21 odd">
	<td class="column-1">The Worldwide Cleaning Industry Association</td><td class="column-2">2005</td><td class="column-3">358</td>
</tr>
<tr class="row-22 even">
	<td class="column-1">(ISSA) Member Code of Ethics</td><td class="column-2"></td><td class="column-3"></td>
</tr>
<tr class="row-23 odd">
	<td class="column-1"></td><td class="column-2"></td><td class="column-3"></td>
</tr>
</tbody>
</table>
<!-- #tablepress-94-no-2 from cache -->
<p><a href="http://creativecommons.org/licenses/by/4.0/" rel="license"><img src="https://i.creativecommons.org/l/by/4.0/88x31.png" alt="Creative Commons License" /></a><br />
Unless otherwise specified, all work in this journal is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>.</p>
 
					
					
					
										</div>
	</div>
<div id='footnote_div'><ol class="footnotes"><li id="footnote_0_2305" class="footnote">Author order is reverse-alphabetical and reflects equal contributions to the project by both authors. This work was supported by a grant from the Center for Technology, Society, and Policy at the University of California Berkeley. We would also like to thank Nick Seaver, Daniel Greene, Tanya E. Clement, Brian Beaton, Amelia Acker and an anonymous reviewer. [<a href="#identifier_0_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_1_2305" class="footnote">Brent Mittelstadt, "Ethics of the Health-Related Internet of Things: a Narrative Review," <em>Ethics and Information Technology </em>19, no. 3 (September 15, 2017): 157-75, doi:10.1007/s10676-017-9426-4; A D I Kramer, J E Guillory, and J T Hancock, "Experimental Evidence of Massive-Scale Emotional Contagion Through Social Networks," <em>Proceedings of the National Academy of Sciences </em>111, no. 24 (June 17, 2014): 8788-90, doi:10.1073/pnas.1320040111; Michal Kosinski et al., "Manifestations of User Personality in Website Choice and Behaviour on Online Social Networks," <em>Machine Learning </em>95, no. 3 (October 19, 2013): 357-80, doi:10.1007/s10994-013-5415-y; Gillinder Bedi et al., "Automated Analysis of Free Speech Predicts Psychosis Onset in High-Risk Youths.," <em>Npj Schizophrenia </em>1 (January 1, 2015): 15030-30, doi:10.1038/npjschz.2015.30; Lemi Baruh and Mihaela Popescu, "Big Data Analytics and the Limits of Privacy Self-Management," <em>New Media &amp; Society </em>19, no. 4 (October 9, 2015): 579-96, doi:10.1177/1461444815614001. [<a href="#identifier_1_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_2_2305" class="footnote">Brian Beaton, Amelia Acker, Lauren Di Monte, Shivrang Setlur, Tonia Sutherland, and Sarah E Tracy, "Debating Data Science," <em>Radical History Review </em>2017, no. 127 (March 2, 2017): 133-48. doi:10.1215/01636545-3690918. [<a href="#identifier_2_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_3_2305" class="footnote">Brian Beaton, "How to Respond to Data Science: Early Data Criticism by Lionel Trilling," <em>Information &amp; Culture: a Journal of History </em>51, no. 3 (August 2016): 352-72. doi:10.7560/IC51303. [<a href="#identifier_3_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_4_2305" class="footnote">"Code of Ethics," <em>Data for Democracy</em>, accessed June 2, 2018, http://datafordemocracy.org/projects/ethics.html. [<a href="#identifier_4_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_5_2305" class="footnote">For an analysis of ethics statements in the AI context, see Daniel Greene, Anna Lauren Hoffmann, and Luke Stark (forthcoming), "<a href="http://dmgreene.net/wp-content/uploads/2018/11/Greene-Hoffmann-Stark-Better-Nicer-Clearer-Fairer-HICSS-Final-Submission.pdf">Better, nicer, clearer, fairer: A critical assessment of the movement for ethical artificial intelligence and machine learning</a>," 52nd Hawaii International Conference on Systems Science. [<a href="#identifier_5_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_6_2305" class="footnote">Kath Albury et al., "Data Cultures of Mobile Dating and Hook-Up Apps: Emerging Issues for Critical Social Science Research," <em>Big Data &amp; Society </em>4, no. 2 (July 3, 2017): 205395171772095-11, 135, doi:10.1177/2053951717720950. [<a href="#identifier_6_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_7_2305" class="footnote">Harold L Wilensky, "The Professionalization of Everyone?," <em>American Journal of Sociology </em>70, no. 2 (September 1964): 137-58. [<a href="#identifier_7_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_8_2305" class="footnote">Mark S. Frankel, "Professional Codes: Why, How, and with What Impact?," <em>Journal of Business Ethics </em>8, no. 2 (1989): 109-15; Bruce R Gaumnitz and John C Lere, "A Classification Scheme for Codes of Business Ethics," <em>Journal of Business Ethics</em>49 (2004): 329-35; Michael Davis, "The Ethics Boom: What and Why," <em>The Centennial Review </em>34, no. 2 (1990): 163-86. [<a href="#identifier_8_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_9_2305" class="footnote">Gaumnitz and Lere, "A Classification Scheme for Codes of Business Ethics;" Muel Kaptein and Johan Wempe, "Twelve Gordian Knots When Developing an Organizational Code of Ethics,"<em>Journal of Business Ethics </em>17, no. 8 (June 1998): 853-69.Alan Gewirth, "Professional Ethics: the Separatist Thesis," <em>Ethics </em>96, no. 2 (January 1986): 282-300; Andrew Abbott, "Professional Ethics," <em>American Journal of Sociology </em>88, no. 5 (March 1983): 855-85. [<a href="#identifier_9_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_10_2305" class="footnote">Abbott, "Professional Ethics," 856. [<a href="#identifier_10_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_11_2305" class="footnote">Abbott, "Professional Ethics." [<a href="#identifier_11_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_12_2305" class="footnote">Jacob Metcalf, "Ethics Codes: History, Context, and Challenges," <em>Council for Big Data, Ethics, and Society</em>, November 9, 2014. [<a href="#identifier_12_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_13_2305" class="footnote">Metcalf, "Ethics Codes: History, Context, and Challenges," 863. [<a href="#identifier_13_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_14_2305" class="footnote">Frankel, "Professional Codes: Why, How, and with What Impact?" [<a href="#identifier_14_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_15_2305" class="footnote">Frankel, "Professional Codes: Why, How, and with What Impact?," 109. [<a href="#identifier_15_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_16_2305" class="footnote">Heinz C. Luegenbiehl, "Codes of Ethics and the Moral Education of Engineers," <em>Business Professional Ethics Journal</em>2, no. 4 (1983): 41-61. [<a href="#identifier_16_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_17_2305" class="footnote">Michael Davis, "Thinking Like an Engineer: the Place of a Code of Ethics in the Practice of a Profession," <em>Philosophy &amp; Public Affairs </em>20, no. 2 (1991): 150-67. [<a href="#identifier_17_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_18_2305" class="footnote">Effy Oz, "Ethical Standards for Computer Professionals: a Comparative Analysis of Four Major Codes," <em>Journal of Business Ethics </em>12, no. 9 (September 1993): 709-26. [<a href="#identifier_18_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_19_2305" class="footnote">Metcalf, "Ethics Codes: History, Context, and Challenges." [<a href="#identifier_19_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_20_2305" class="footnote">Metcalf, "Ethics Codes: History, Context, and Challenges." [<a href="#identifier_20_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_21_2305" class="footnote">Oz,"Ethical Standards for Computer Professionals: a Comparative Analysis of Four Major Codes." [<a href="#identifier_21_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_22_2305" class="footnote">Don Gotterbarn and James H Moor, "Virtual Decisions: Video Game Ethics, Just Consequentialism, and Ethics on the Fly," <em>SIGCAS Computers and Society </em>39, no. 3 (December 2009): 27-42. [<a href="#identifier_22_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_23_2305" class="footnote">Rob Kitchin, "Big Data, New Epistemologies and Paradigm Shifts," <em>Big Data &amp; Society </em>1, no. 1 (April 2014): 205395171452848-12, doi:10.1177/2053951714528481. [<a href="#identifier_23_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_24_2305" class="footnote">Mark Nunes, "Baudrillard in Cyberspace: Internet, Virtuality, and Postmodernity," <em>Style </em>29 (1995): 314-27; Sally Wyatt, "Danger! Metaphors at Work in Economics, Geophysiology, and the Internet," <em>Science, Technology, &amp; Human Values </em>29, no. 2 (August 18, 2016): 242-61, doi:10.1177/0162243903261947; Rowan Wilken, "An Exploratory Comparative Analysis of the Use of Metaphors in Writing on the Internet and Mobile Phones," <em>Social Semiotics </em>23, no. 5 (November 2013): 632-47, https://towardsdatascience.com/big-data-metaphors-we-live-by-98d3fa44ebf8. [<a href="#identifier_24_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_25_2305" class="footnote">as Teun A. van Dijk,"Principles of Critical Discourse Analysis," <em>Discourse &amp; Society</em>4, no. 2 (1993): 249-83; "Critical Discourse Analysis," in <em>The Handbook of Discourse Analysis</em>, (West Sussex, UK: Wiley, 2015), 466-85. [<a href="#identifier_25_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_26_2305" class="footnote">van Dijk, "Critical Discourse Analysis," 473. [<a href="#identifier_26_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_27_2305" class="footnote">Rowan Wilken, "An Exploratory Comparative Analysis of the Use of Metaphors in Writing on the Internet and Mobile Phones,"<em>Social Semiotics </em>23, no. 5 (November 2013): 632-47, doi:10.1080/10350330.2012.738999. [<a href="#identifier_27_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_28_2305" class="footnote">Wilken,"An Exploratory Comparative Analysis," 642. [<a href="#identifier_28_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_29_2305" class="footnote">Dawn Nafus,"Stuck Data, Dead Data, and Disloyal Data: the Stops and Starts in Making Numbers Into Social Practices," <em>Distinktion: Journal of Social Theory </em>15, no. 2 (June 17, 2014): 208-22, doi:10.1080/1600910X.2014.920266. [<a href="#identifier_29_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_30_2305" class="footnote">Stewart Brand, <em>The Media Lab</em>, (New York: Viking Penguin, 1987), 202. [<a href="#identifier_30_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_31_2305" class="footnote">Cornelius Puschmann and Jean Burgess, "Big Data, Big Questions| Metaphors of Big Data," <em>International Journal of Communication </em>8 (2014). [<a href="#identifier_31_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_32_2305" class="footnote">Puschmann and Burgess, "Big Data, Big Questions," 1700. [<a href="#identifier_32_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_33_2305" class="footnote">Puschmann and Burgess, "Big Data, Big Questions," 1699. [<a href="#identifier_33_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_34_2305" class="footnote">The now-ubiquitous metaphor of "cloud" computing has similar resonances, though it captures data as vaporous<span class="emdash">—</span>somewhere between an invisible gas and a suffocating liquid. [<a href="#identifier_34_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_35_2305" class="footnote">Deborah Lupton, "<a href="https://simplysociology.wordpress.com/2013/10/29/swimming-or-drowning-in-the-data-ocean-thoughts-on-the-metaphors-of-big-data/">Swimming or Drowning in the Data Ocean? Thoughts on the Metaphors of Big Data</a>," <em>The Sociological Life</em>, October 29, 2013. [<a href="#identifier_35_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_36_2305" class="footnote">Sara M. Watson, "Metaphors of Big Data," <em>DIS Magazine</em>, May 28, 2016. [<a href="#identifier_36_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_37_2305" class="footnote">Kailash Awati and Simon Buckingham Shum, "<a href="https://medium.com/@sbskmi/big-data-metaphors-we-live-by-79ba2fbd1423">Big Data Metaphors We Live by</a>," <em>Towards Data Science</em>, May 14, 2015. [<a href="#identifier_37_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_38_2305" class="footnote">Cory Doctorow, "<a href="https://www.theguardian.com/technology/2008/jan/15/data.security">Why Personal Data Is Like Nuclear Waste</a>," <em>The Guardian</em>, January 15, 2008.)Metaphors referencing more quotidian forms of waste also point toward the similarly quotidian forms of work involved in data science: are those who work with data "rock stars" or "data janitors"<span class="emdash">—</span>or both?((Lilly Irani, "<a href="http://www.publicbooks.org/justice-for-data-janitors/">Justice for 'Data Janitors'</a>," <em>Public Books</em>, January 15, 2015. [<a href="#identifier_38_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_39_2305" class="footnote">There is one notable<span class="emdash">—</span>and noxious<span class="emdash">—</span>analogy which does foreground people: "big data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so everyone claims they are doing it...." Posted to Facebook in 2013 by Dan Ariely, Professor at Duke University, the phrase has since been popularized in numerous blog posts, news articles, and talks. We have deliberately omitted this analogy, however, as we find it more problematic than insightful. Specifically, we do not wish to contribute to the sexualization of technological work<span class="emdash">—</span>a process * often serves to exclude or marginalize women in STEM<span class="emdash">—</span>or engage in the belittling of young persons' sexual development. While other work may find constructive connections between sexual ethics and data ethics broadly (see, for example, work on the ethics of consent: Una Lee and Dann Toliver, <em><a href="http://ripplemap.io/zine.pdf">Building Consentful Tech</a>,</em> Toronto, ON: And Also Too, 2017.), we do not find this particular analogy productive. [<a href="#identifier_39_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_40_2305" class="footnote">Hwang and Levy, "'The Cloud' and Other Dangerous Metaphors." [<a href="#identifier_40_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_41_2305" class="footnote">Kavita Philip, "Nature, Culture Capital, Empire," <em>Capitalism Nature Socialism </em>18, no. 1 (March 2007): 5-12, doi:10.1080/10455750601164584. [<a href="#identifier_41_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_42_2305" class="footnote">Irina Raicu, "<a href="http://on.recode.net/1PnhhgD">Metaphors of Big Data</a>," <em>Recode</em>, February 26, 2016. [<a href="#identifier_42_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_43_2305" class="footnote">The CSEP's Ethics Code Collection is available at http://ethicscodescollection.org. For further information on the CSEP's collection and update policy, please see <a href="http://ethics.iit.edu/ecodes/node/5421">http://ethics.iit.edu/ecodes/node/5421</a>. [<a href="#identifier_43_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_44_2305" class="footnote">Jeff Hammerbacher, "Information Platforms and the Rise of the Data Scientist," in <em>Beautiful Data: the Stories Behind Elegant Data Solutions</em>, ed. Toby Segaran and Jeff Hammerbacher, (Sebastopol, CA, 2009), 73-84. [<a href="#identifier_44_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_45_2305" class="footnote">Oliver L. Haimson and Anna Lauren Hoffmann, "Constructing and Enforcing 'Authentic' Identity Online: Facebook, Real Names, and Non-Normative Identities," <em>First Monday </em>21, no. 6 (June 6, 2016), doi: <a href="http://dx.doi.org/10.5210/fm.v21i6.6791">http://dx.doi.org/10.5210/fm.v21i6.6791</a>; Anna Lauren Hoffmann, Nicholas Proferes, and Michael Zimmer, "'Making the World More Open and Connected': Mark Zuckerberg and the Discursive Construction of Facebook and Its Users," <em>New Media &amp; Society </em>12, no. 1 (January 13, 2017): 146144481666078-20, doi:10.1177/1461444816660784. [<a href="#identifier_45_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_46_2305" class="footnote">Maude Standish, "<a href="https://www.huffingtonpost.com/maude-standish/data-is-the-new-astrology_b_3150148.html">Data Is the New Astrology</a>," <em>The Huffington Post</em>, April 25, 2013; Kate Crawford, "Asking the Oracle," in <em>Laura Poitras: Astro Noise</em>, (New York/New Haven, CT, 2016), 138-53. [<a href="#identifier_46_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_47_2305" class="footnote">Theo van Leeuwen, <em>Discourse and Practice: New Tools for Critical Discourse Analysis </em>(Oxford Studies in Sociolinguistics), Oxford: Oxford University Press, 2008. [<a href="#identifier_47_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_48_2305" class="footnote">van Dijk, "Critical Discourse Analysis," 466. [<a href="#identifier_48_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_49_2305" class="footnote">H. F. Hsieh, "Three Approaches to Qualitative Content Analysis," <em>Qualitative Health Research </em>15, no. 9 (November 1, 2005): 1277-88, doi:10.1177/1049732305276687. [<a href="#identifier_49_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_50_2305" class="footnote">Gaumnitz and Lere, "A Classification Scheme for Codes of Business Ethics." [<a href="#identifier_50_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_51_2305" class="footnote">Abbot, "Professional Ethics." [<a href="#identifier_51_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_52_2305" class="footnote">Ethics codes thus perform for professionals in the abstract what the interaction design of many digital platforms does for gig workers in practice: figure their subjects as "moral liability sponges" or "moral crumple zones." See Alex Rosenblat and Luke Stark, "Algorithmic Labor and Information Asymmetries: a Case Study of Uber's Drivers," <em>The International Journal of Communication </em>10 (July 27, 2016): 3758-84; and M. C. Elish, "Moral Crumple Zones: Cautionary Tales in Human-Robot Interaction" (We Robot 2016) (March 20, 2016). We Robot 2016 Working Paper. Available at SSRN: <a href="https://ssrn.com/abstract=2757236">https://ssrn.com/abstract=2757236</a> or <a href="http://dx.doi.org/10.2139/ssrn.2757236">http://dx.doi.org/10.2139/ssrn.2757236</a>  [<a href="#identifier_52_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_53_2305" class="footnote">David Lyon, ed., <em>Surveillance as Social Sorting: Privacy, Risk and Digital Discrimination</em>, (New York: Routledge, 2003); Herman Tavani, "Privacy Enhancing Technologies as a Panacea for Online Privacy Concerns: Some Ethical Considerations," <em>Journal of Information Ethics </em>9, no. 2 (2000); Helen Nissenbaum, "Respecting Context to Protect Privacy: Why Meaning Matters," <em>Science and Engineering Ethics </em>109, no. 4 (July 11, 2015): 1-22, doi:10.1007/s11948-015-9674-9. [<a href="#identifier_53_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_54_2305" class="footnote">Brian Beaton, "How to Respond to Data Science: Early Data Criticism by Lionel Trilling," <em>Information &amp; Culture: a Journal of History </em>51, no. 3 (August 2016): 352-72. doi:10.7560/IC51303. [<a href="#identifier_54_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_55_2305" class="footnote">Patricia Ticineto Clough and Craig Willse, "Gendered Security/National Security: Political Branding and Population Racism," March 7, 2013; Michel Foucault Collège de France, <em>The Birth of Biopolitics: Lectures at the Collège De France, 1978-1979</em>, 1st ed., (New York: Picador, 2010); Matthew B Sparke, "A Neoliberal Nexus: Economy, Security and the Biopolitics of Citizenship on the Border," <em>Political Geography </em>no. 25, no. 25 (2006): 151-80, doi:10.1016/j.polgeo.2005.10.002. [<a href="#identifier_55_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_56_2305" class="footnote">Gabriel Abend, <em>The Moral Background</em> (Princeton, NJ and Oxford: Princeton University Press, 2014). [<a href="#identifier_56_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_57_2305" class="footnote">Tavani, "The State of Computer Ethics as a Philosophical Field of Inquiry;" Frances S. Grodzinsky and Herman T. Tavani, "Applying the 'Contextual Integrity' Model of Privacy to Personal Blogs in the Blogosphere," <em>International Journal of Internet Research Ethics </em>3 (December 30, 2010): 38-47; Lucas D. Introna, "Maintaining the Reversibility of Foldings: Making the Ethics (Politics) of Information Technology Visible," <em>Ethics and Information Technology </em>9, no. 1 (December 21, 2006): 11-25, doi:10.1007/s10676-006-9133-z. [<a href="#identifier_57_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_58_2305" class="footnote">Literature on the concept of "securitization" supports this view: when topics of public debate are securitized, they are removed from the realm of political contestation and deemed to be technical matters addressable by experts. See Lene Hansen and Helen Nissenbaum, "Digital Disaster, Cyber Security, and the Copenhagen School," <em>International Studies Quarterly </em>53 (2009): 1155-75; Helen Nissenbaum, "Where Computer Security Meets National Security," <em>Ethics and Information Technology </em>7 (2005): 61-73, doi:10.1007/s10676-005-4582-3. [<a href="#identifier_58_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_59_2305" class="footnote">It is worth noting that The Wildlife Society does address unspecified "stakeholders" in the well-being of certain wildlife species. These stakeholders could easily include oppressed individuals or groups deserving of particular consideration, especially native or indigenous peoples. However, these groups are not specifically named in the code. [<a href="#identifier_59_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_60_2305" class="footnote">"<a href="http://www.nfda.org/about-nfda">About NFDA</a>," <em>National Funeral Directors Association</em>, June 9, 2018. [<a href="#identifier_60_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_61_2305" class="footnote">Solon Barocas and Andrew D. Selbst, "Big Data's Disparate Impact," California Law Review 104 (2016): 671-732. doi:10.15779/Z38BG31; Chelsea Barabas, Madars Virza, Karthik Dinakar, Joichi Ito, and Jonathan Zittrain, "Interventions Over Predictions - Reframing the Ethical Debate for Actuarial Risk Assessment," Proceedings of Machine Learning Research 81:1-15, 2018. [<a href="#identifier_61_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_62_2305" class="footnote">Anna Lauren Hoffmann, "Data Violence and How Bad Engineering Choices Can Damage Society," <em>Medium </em>(Member Feature Story), 30 April 2018, available at <a href="https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4">https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4</a> [<a href="#identifier_62_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_63_2305" class="footnote">Linda D. Molm, Nobuyuki Takahashi, and Gretchen Peterson, "Risk and Trust in Social Exchange: an Experimental Test of a Classical Proposition," <em>The American Journal of Sociology </em>105, no. 5 (March 2000): 1396-1427; Susan P. Shapiro, "The Social Control of Impersonal Trust," <em>American Journal of Sociology </em>93, no. 3 (November 1987): 623-58; Guido Möllering, "The Trust/Control Duality," <em>International Sociology </em>20, no. 3 (June 29, 2016): 283-305, doi:10.1177/0268580905055478. [<a href="#identifier_63_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_64_2305" class="footnote">Matthew K. O. Lee and Efraim Turban, "A Trust Model for Consumer Internet Shopping," <em>International Journal of Electronic Commerce </em>6, no. 1 (October 1, 2001): 75-91, doi:10.2307/27751003?ref=search-gateway:65426dfa915042907ae6237cf88297e1; David Gefen, Izak Benbasat, and Paula Pavlou, "A Research Agenda for Trust in Online Environments," <em>Journal of Management Information Systems </em>24, no. 4 (May 12, 2008): 275-86, doi:10.2753/MIS0742-1222240411. [<a href="#identifier_64_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_65_2305" class="footnote">James I. Charlton, <em>Nothing About Us Without Us: Disability Oppression and Empowerment</em>, (Berkeley and Los Angeles: University of California Press, 1998). [<a href="#identifier_65_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_66_2305" class="footnote">Noëmi Manders-Huits and Michael Zimmer, "Values and Pragmatic Action: The Challenges of Introducing Ethical Intelligence in Technical Design Communities," <em>International Review of Information Ethics</em>, January 30, 2009, 1-8. [<a href="#identifier_66_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_67_2305" class="footnote">Kate Conger, "<a href="https://gizmodo.com/google-plans-not-to-renew-its-contract-for-project-mave-1826488620">Google Plans Not to Renew Its Contract for Project Maven, a Controversial Pentagon Drone AI Imaging Program</a>," <em>Gizmodo</em>, June 1, 2018. [<a href="#identifier_67_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_68_2305" class="footnote">Daniel Greene, Anna Lauren Hoffmann, and Luke Stark, "Better, Nicer, Clearer, Fairer: A Critical Assessment of the Movement for Ethical Artificial Intelligence and Machine Learning," Hawaii International Conference on System Sciences (HICSS 2019), Maui, HI. [<a href="#identifier_68_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_69_2305" class="footnote">Mark Latonero, <em>Governing Artificial Intelligence: Upholding Human Rights and Dignity</em>, Data &amp; Society Research Institute, (10 October 2018), available at https://datasociety.net/output/governing-artificial-intelligence/; Ron Dudai, "Human Rights in the Populist Era: Mourn then (Re)Organize," <em>Journal of Human Rights Practice </em>9, no. 1 (February 2017): 16-21. <a href="https://doi.org/10.1093/jhuman/hux005">https://doi.org/10.1093/jhuman/hux005</a> [<a href="#identifier_69_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_70_2305" class="footnote">Jack M. Balkin, "Information Fiduciaries and the First Amendment," <em>UC Davis Law Review </em>49, no. 4 (April 2016): 1183-1234. [<a href="#identifier_70_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_71_2305" class="footnote">Jack M. Balkin and Jonathan Zittrain, "<a href="https://www.theatlantic.com/technology/archive/2016/10/information-fiduciary/502346/">A Grand Bargain to Make Tech Companies Trustworthy</a>," <em>The Atlantic</em>, October 3, 2016. [<a href="#identifier_71_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_72_2305" class="footnote">Doug Hulette, "<a href="https://www.cs.princeton.edu/news/patrolling-intersection-computers-and-people">Patrolling the Intersection of Computers and People</a>," <em>Princeton University Computer Science</em>, October 2, 2017. [<a href="#identifier_72_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_73_2305" class="footnote">Rebecca Lemov, "'<a href="https://aeon.co/essays/why-big-data-is-actually-small-personal-and-very-human">Big data is people!</a>'" <em>Aeon Magazine</em>, June 16, 2016. [<a href="#identifier_73_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_74_2305" class="footnote">Theo van Leeuwen<em>, Discourse and Practice: New Tools for Critical Discourse Analysis </em>(Oxford Studies in Sociolinguistics), Oxford: Oxford University Press, 2008, 105. [<a href="#identifier_74_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_75_2305" class="footnote">Langdon Winner, Testimony to the Committee on Science of the U.S. House of Representatives on The Societal Implications of Nanotechnology, 9 April 2003, available at <a href="http://homepages.rpi.edu/~winner/testimony.htm">http://homepages.rpi.edu/~winner/testimony.htm</a>. [<a href="#identifier_75_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_76_2305" class="footnote">Katie Shilton,"Values Levers: Building Ethics Into Design," <em>Science, Technology, &amp; Human Values </em>38, no. 3 (May 2013): 374-97, doi:10.1177/0162243912436985. [<a href="#identifier_76_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_77_2305" class="footnote">Michael Skirpan et al., "Ethics Education in Context," (the 49th ACM Technical Symposium, New York, New York, USA: ACM Press, 2018), 940-45, doi:10.1145/3159450.3159573; [Author, 2018]; Costanza-Chock, "Design Justice: Towards an Intersectional Feminist Framework for Design Theory and Practice." [<a href="#identifier_77_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_78_2305" class="footnote">Mary Flanagan and Helen Nissenbaum, <em>Values at Play in Digital Games</em>, (Cambridge, MA: The MIT Press, 2014); Phoebe Sengers et al., "Reflective Design," (Proceedings of the 4th Decennial Aarhus Conference, Aarhus, Denmark, 2005), 49-58; Batya Friedman, Peter H. Kahn, and Alan Borning, "Value Sensitive Design and Information Systems," in <em>Human-Computer Interaction in Management Information Systems: Foundations</em>, ed. B. Schneiderman, Ping Zhang, and D. Galletta, (New York: M.E. Sharpe, Inc., 2006), 348-72. [<a href="#identifier_78_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_79_2305" class="footnote">Hoffmann, "Data Violence." [<a href="#identifier_79_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_80_2305" class="footnote">Sasha Costanza-Chock, "Design Justice: Towards an Intersectional Feminist Framework for Design Theory and Practice," 2018, 1-14, doi:10.21606/dma.2017.679. [<a href="#identifier_80_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_81_2305" class="footnote">Kate Crawford, "AI Now: Social and Political Questions for Artificial Intelligence," (University of Washington, March 6, 2018), available at: <a href="https://www.youtube.com/watch?v=a2IT7gWBfaE">https://www.youtube.com/watch?v=a2IT7gWBfaE</a>. [<a href="#identifier_81_2305" class="footnote-link footnote-back-link">↩</a>]</li><li id="footnote_82_2305" class="footnote">Batya Friedman and Helen Nissenbaum, "Bias in Computer Systems," <em>ACM Transactions on Information Systems </em>14, no. 3 (September 5, 1996): 330-47; Joy Buolamwini and Timnit Gebru, "Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification," <em>Proceedings of Machine Learning Research </em>81 (2018): 1-15. [<a href="#identifier_82_2305" class="footnote-link footnote-back-link">↩</a>]</li></ol></div>