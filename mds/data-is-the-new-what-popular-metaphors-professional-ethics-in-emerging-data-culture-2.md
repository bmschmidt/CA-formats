---
author: Luke Stark and Anna Lauren Hoffmann 
date: '05.02.19'
shortauthor: Luke Stark and Anna Lauren Hoffmann 
shorttitle: |
    Data Is the New What? Popular Metaphors & Professional Ethics in
    Emerging Data Culture
title: |
    Data Is the New What? Popular Metaphors & Professional Ethics in
    Emerging Data Culture
---

::: {.entry .print-only}
::: {#post-2305 .post-2305 .post .type-post .status-publish .format-standard .has-post-thumbnail .hentry .category-articles}
###### *Peer-Reviewed By: A[nonymous and Dr. Brian Beaton]{lang="EN-CA" lang="EN-CA"}*

###### *Clusters: [Data](http://culturalanalytics.org/2018/01/data/),[Infrastructure](http://culturalanalytics.org/2018/11/infrastructure/)*

###### *Article DOI: [10.22148/16.036](https://culturalanalytics.org/2019/05/data-is-the-new-what-popular-metaphors-professional-ethics-in-emerging-data-culture-2/)*

###### *PDF DOI: [10.31235/osf.io/2xguw](https://doi.org/10.31235/osf.io/2xguw)*

###### *Journal ISSN: 2371-4549*

###### *Cite: Luke Stark and Anna Lauren Hoffmann, "Data Is the New What? Popular Metaphors &amp; Professional Ethics in Emerging Data Culture," Journal of Cultural Analytics. May 2, 2019. DOI: [10.31235/osf.io/2xguw](https://doi.org/10.31235/osf.io/2xguw)*

 

A growing list of high-profile controversies involving the social
impacts of artificial intelligence systems (AI), digital data collection
and algorithmic analysis have forced difficult conversations around the
ethics of data-intensive digital technologies and so-called "big data"
research.^[1](#footnote_0_2305 "Author order is reverse-alphabetical and reflects equal contributions to the project by both authors. This work was supported by a grant from the Center for Technology, Society, and Policy at the University of California Berkeley. We would also like to thank Nick Seaver, Daniel Greene, Tanya E. Clement, Brian Beaton, Amelia Acker and an anonymous reviewer."){#identifier_0_2305
.footnote-link
.footnote-identifier-link}[2](#footnote_1_2305 "Brent Mittelstadt, “Ethics of the Health-Related Internet of Things: a Narrative Review,” Ethics and Information Technology 19, no. 3 (September 15, 2017): 157–75, doi:10.1007/s10676-017-9426-4; A D I Kramer, J E Guillory, and J T Hancock, “Experimental Evidence of Massive-Scale Emotional Contagion Through Social Networks,” Proceedings of the National Academy of Sciences 111, no. 24 (June 17, 2014): 8788–90, doi:10.1073/pnas.1320040111; Michal Kosinski et al., “Manifestations of User Personality in Website Choice and Behaviour on Online Social Networks,” Machine Learning 95, no. 3 (October 19, 2013): 357–80, doi:10.1007/s10994-013-5415-y; Gillinder Bedi et al., “Automated Analysis of Free Speech Predicts Psychosis Onset in High-Risk Youths.,” Npj Schizophrenia 1 (January 1, 2015): 15030–30, doi:10.1038/npjschz.2015.30; Lemi Baruh and Mihaela Popescu, “Big Data Analytics and the Limits of Privacy Self-Management,” New Media & Society 19, no. 4 (October 9, 2015): 579–96, doi:10.1177/1461444815614001."){#identifier_1_2305
.footnote-link .footnote-identifier-link}^These incidents are directly
relevant to newly coalescing cultures of "data science," an emergent
field which seeks both to interpret and capitalize on the creation,
collection, and processing of knowledge through large collections of
digital data, often in conjunction with particular techniques like
machine learning (ML).[^1] The long list of recent public controversies,
as Brian Beaton observes, lays bare data science's extant lack of
direction regarding professional ethics or values.[^2]

Various groups have ventured into this conceptual gap to advance
principles or guidelines for doing ethical data science. In 2017, for
example, digital organization Data for Democracy (D4D)[---]{.emdash}in
partnership with media conglomerate Bloomberg and open source platform
BrightHive[---]{.emdash}announced an effort to crowdsource a code of
ethics for data scientists, seeking to "define values and priorities for
overall ethical behavior, in order to guide a data scientist in being a
thoughtful, responsible agent of change."[^3]This recent focus on
developing ethical codes for data science (alongside related areas such
as AI/ML) suggests the field seeks to address its social impacts through
discourses and processes of professional consolidation.[^4] Yet such
efforts raise further questions. What kind of work counts as "data
science" in the first place? What are its aims and historical
precursors? And what, if any, baseline ethical commitments bind
disparately situated researchers, analysts, and (of course) professional
data scientists?

As data science seeks to constitute itself as a professional field,
these questions will continue to lurk in the background of efforts to
articulate and codify data science's ethical commitments. In this paper,
we examine one dimension of this conceptual terrain: the relevance and
resonance of extant codes of professional and research ethics
in[---]{.emdash}and beyond[---]{.emdash}domains related to computing,
information science, and data analytics. The paper proceeds in four
parts. In the first, we draw on work in the history and sociology of
professional ethics to establish the (often fraught) relationship
between ethical codes, professionalization, and moral responsibility,
with a focus on ethics codes in domains conventionally allied with data
science such as computing and information science. Second, we expand the
domain of potentially relevant professional analogues by reviewing and
drawing inspiration from many of the popular metaphors for
"data"[---]{.emdash}and by extension, the work of data
scientists[---]{.emdash}proliferating in both popular and academic
settings.

In the third and fourth sections, we employ discourse analysis to assess
two sets of professional ethics codes: one set rooted in conventionally
allied domains like computing; the other derived from those professions
evoked by the metaphors associated with data and data science. Through
this discursive analysis, we develop a number of insights regarding the
challenges and opportunities of developing a code of ethics for data
science, and by extension the ambivalent role of data science as a
profession within a broader tapestry of "data cultures."[^5]With
multiple metaphors for what "big data" is and can do, and multiple
potentially relevant ethics codes scattered across different domains,
data ethics is a field in flux. Collectively, these conversations
represent an effort to better grapple with the consequences of the
language we use for understanding and working with
data[---]{.emdash}"big" or otherwise[---]{.emdash}today, and how our
discourses around data cultures shape their material, cultural, and
political impact.

Ethics Codes As/And Professional Cultures {#ethics-codes-asand-professional-cultures style="text-align: center;"}
=========================================

Codes of ethics are longstanding mechanisms through which groups of
experts have sought to define themselves and their priorities as
"professionals," or recognized members of particular
professions.[^6]High-status professions such as doctors, lawyers and
engineers pioneered professional ethics codes as early as the eighteenth
century. Today, many other groups of experts[---]{.emdash}from foresters
to firefighters to astrologers[---]{.emdash}have enacted these codes as
signals, sometimes merely aspirational, of their professional status.
Ongoing historical and sociological work in this area has shown such
codes can and have served a range of valuable functions, from educating
professionals and instilling positive group norms to setting benchmarks
against which unethical behavior may be
censured.^[9](#footnote_8_2305 "Mark S. Frankel, “Professional Codes: Why, How, and with What Impact?,” Journal of Business Ethics 8, no. 2 (1989): 109–15; Bruce R Gaumnitz and John C Lere, “A Classification Scheme for Codes of Business Ethics,” Journal of Business Ethics49 (2004): 329–35; Michael Davis, “The Ethics Boom: What and Why,” The Centennial Review 34, no. 2 (1990): 163–86."){#identifier_8_2305
.footnote-link
.footnote-identifier-link}[10](#footnote_9_2305 "Gaumnitz and Lere, “A Classification Scheme for Codes of Business Ethics;” Muel Kaptein and Johan Wempe, “Twelve Gordian Knots When Developing an Organizational Code of Ethics,”Journal of Business Ethics 17, no. 8 (June 1998): 853–69.Alan Gewirth, “Professional Ethics: the Separatist Thesis,” Ethics 96, no. 2 (January 1986): 282–300; Andrew Abbott, “Professional Ethics,” American Journal of Sociology 88, no. 5 (March 1983): 855–85."){#identifier_9_2305
.footnote-link .footnote-identifier-link}^Most important for present
purposes, a profession's ethical code offers insight into how it
collectively understands and seeks to modulate the distribution of
obligations between individual practitioners, other individuals or
stakeholders, and society more broadly.[^7]

In his survey of the history of professional ethics codes, Andrew Abbot
demonstrates the ubiquity of such codes as a key element of industrial
state/social formation, representing perhaps "the most concrete cultural
form in which professions acknowledge their societal
obligations."[^8]These codes do not arise in theoretical or conceptual
vacuums. As Jacob Metcalf writes of research ethics, they represent
"hard-won responses to major disruptions, especially medical and
behavioral research scandals."[^9]In addition, ethics codes are enforced
most often when ethical infractions or controversies are highly visible.
As Abbot notes, "general public service obligations are extremely
important as claims but extremely vague as rules."[^10]Mark Frankel
likewise notes a relationship between \"professions' pursuit of
autonomy,[^11]and the public's demand for accountability.\"[^12] In view
of this tension between visibility and vagueness, ethics codes often
elide granular attention to professional activities, relying instead on
informal everyday rules over which individual practitioners have some
(albeit limited) control.

Fundamental to these debates is the question of whether a professional
ethics code should be a fine-grained "how-to" manual or a set of broad
principles to be inculcated into an individual. These questions are
particularly evident in the history of engineering codes and engineering
ethics.[^13]For engineers, there remains a tension in the inherent
definition of a profession as a group of experts explicitly set to serve
the general public, and a profession's own interests as a particular
group.[^14]Extant conversations surrounding codes of ethics for
computing mirror these disagreements.[^15]As Metcalf observes, the
current surge of practitioner and public interest in ethics of data
science was paralleled by a flurry of work in the early 1990s by major
international professional organizations[---]{.emdash}including the
Association of Computing Machinery (ACM) and the Institute of Electrical
and Electronics Engineers (IEEE)[---]{.emdash}to draft and implement
ethics codes.[^16]Metcalf suggests ethics codes are often reactive,
instituted in response to crises of professional
confidence.[^17]Further, Effy Oz's assessment of ethics codes from four
professional associations involving computing,[^18]including the ACM,
argued the lack of prioritization around moral obligations to various
groups, common to professional ethics codes more generally, is
especially pronounced in professional computing codes.[^19]As Frankel
warns, ethics codes that fail to engage with broader social values and
expectations risk becoming mere "political tools" for signaling moral
virtue to society at large.

Data & Data Science Metaphors {#data-data-science-metaphors style="text-align: center;"}
=============================

If professional codes of ethics are often "hard-won responses to major
disruptions," we should attend to the nature of the "disruption" in
question. Doing so points towards previously underappreciated or
overlooked ethical domains[---]{.emdash}in this case, domains which help
us better come to terms with the rise of the data scientist and an
epistemological shift in how we produce, understand, and act on
knowledge about the world.[^20]Here, we identify additional domains of
ethical consideration relevant to data ethics by turning to the
metaphors we use to talk about data itself.

The metaphors we deploy to make sense of new tools and technologies
serve the dual purpose of highlighting the novel by reference to the
familiar, while also obscuring or abstracting away from some features of
a given technology or practice[^21][---]{.emdash}as Teun A. van Dijk
describes,[^22]metaphors "are powerful means to make abstract mental
models more concrete."[^23]In this way, metaphors[---]{.emdash}Rowan
Wilken notes[^24][---]{.emdash}are never innocent; they "always
influence and shape the meanings that are generated by, and the meanings
which accumulate around, a given metaphor."[^25]For example, as Dawn
Nafus describes in the domain of data visualization,[^26]the idea that
data wants to be freed[---]{.emdash}itself an offshoot of the earlier
claim, "information wants to be free"[^27][---]{.emdash}masks the labor
expended in "freeing" data, especially in cases where data, in the words
of her research subjects, are "stuck" or "disloyal."

Cornelius Puschmann and Jean Burgess describe two predominating groups
of metaphors around contemporary descriptions of data:1) data as a
natural force to be controlled and 2) data as a resource to be
consumed.[^28]As a resource, the authors note data are analogized to
"food and fuel," staple materials which "must be consumed to exist and
to move forward rather than being consciously used."[^29]As a force of
nature, the authors observe data are often described as being in a
liquid state: "allusion to water \[or oil\]" they write, "supports the
notion that data is all at once essential, valuable, difficult to
control, and ubiquitous."[^30]From data lakes, rivers, and oceans to
data floods, deluges, and tsunamis, these metaphors position data as
something massive and volatile while also necessary to support human
life.[^31]As Deborah Lupton notes, however, liquid metaphors also
tacitly work to forestall ethical or regulatory interventions by
positioning data as ubiquitous, uncontrollable, and resistant to
transparency or accountability.[^32]

Both discursive strains[---]{.emdash}data as force and
resource[---]{.emdash}point toward additional metaphors rooted in
industrial production. As Sara M. Watson observes, many of our metaphors
for data in the "knowledge economy" reference older industrial
occupations.[^33]Efforts to think through or propose strategies for
managing data, in particular, rely on appeals to industrial
imagery.[^34]Descriptions of data as "toxic" or "radioactive" evoke
images of massive nuclear facilities and radioactive waste management
experts.[^35]

Curiously, as Tim Hwang and Karen Levy point out, often "people are
nowhere to be found" in this landscape of data metaphors:[^36]the excess
of environmental metaphors for data "do us a disservice by masking the
human behaviors, relationships, and communications that make up all that
data we're streaming and mining."[^37]By analogizing digital data as a
part of the "natural world"[---]{.emdash}the latter term itself a
techno-scientific reification and justification of centuries of imperial
and settler colonial exploitation[^38][---]{.emdash}the status of data
as a record of human activity is doubly occluded.[^39]

Method and Analysis {#method-and-analysis style="text-align: center;"}
===================

To explore the relationships between data science, data metaphors, and
professional ethics, we undertook a comparative discourse analysis of
two sets of text-based data: 1) the text of ethics codes conventionally
accepted as relevant to data science today and 2) the text of ethics
codes from professions associated with popular or dominant data
metaphors. Codes for both sets were accessed through the Center for the
Study of Ethics in the Professions, which indexes more than 2500 codes
and guidelines from over 1500 organizations, dating from 1887 to the
present.[^40] For our first set of codes, we drew from dominant
professional associations in information and computing fields, namely
the Association of Computing Machinery (ACM) and the Institute of
Electrical and Electronics Engineers (IEEE). We also identified major
professional associations in the areas of mathematics and statistics,
like the American Statistical Association. This set of codes provide a
baseline of historically salient professional and ethical concerns in
domains which[---]{.emdash}at least on the surface[---]{.emdash}directly
inform the development, training, and backgrounds of today's data
scientists.[^41]

For the second set, we selected codes that 1) spoke directly to our
identified metaphors/concepts and 2) were of sufficient length and
substance to effectively compare with the well-developed codes in our
first set. For example, if data is often framed as a natural resource,
then we considered professions engaged in the extraction and stewardship
of resources, as with forestry; if big data is considered "radioactive,"
then we looked to professionals tasked with the storage, management, and
safekeeping of radioactive or toxic materials. Data collection was
further informed by our own knowledge of terms and metaphors, derived
from our own experiences working with and educating data scientists (for
example, commonly employed terms like "cleaning,"[---]{.emdash}i.e.
processing[---]{.emdash}data) and studying the ethics and rhetoric of
data-intensive platforms more broadly.[^42]We also drew on discussions
of predictive analytics equating practices of data-driven forecasting
and prediction with the work of astrologers.[^43]Finally, inspired by
descriptions of online data as the material traces humans leave behind
(akin to, say, dead skin cells), we drew on the ethics of funeral
directors and morticians charged with overseeing and caring for human
remains.

In total, we selected 20 ethics codes for analysis. These codes ranged
in length from approximately 330 to 4300 words, with a mean length of
approximately 1300 words and a median length of approximately 800 words.
Many of the codes were undated, with those with dates ranging from 1992
to 2016 (see Appendix A for details). We used the qualitative research
software ATLAS.ti to aid in manual qualitative coding of the corpus
according to principles of critical discourse analysis (CDA).[^44]We
focused, in particular, on CDA's commitment to mark both the *social
actors*and *social actions*explicit and implicit in a given text.[^45]As
professional codes aim to regulate (to varying degrees) the practice of
professionals in a given domain, we were interested first in identifying
those actors (individual or institutional) and actions (encouraged or
prohibited) conceived of as relevant by a given code. In addition, we
also identified and labeled references to any explicit value or virtue
(i.e., "fairness," "honesty," "integrity"), allowing us to connect
specific values to specific actors or practices. As such, our analysis
was "directed," as our coding scheme was derived both before (the
actor/action frame adopted prior to coding) and during (values
identified while coding) the analysis.[^46]

Analysis {#analysis style="text-align: center;"}
========

Despite the broad range of sampled fields and subject areas, ethics
codes in the corpus demonstrated considerable thematic overlap. Much of
this overlap is a matter of genre[---]{.emdash}ethics codes are
recognizable as such precisely because they share certain schematic and
substantive markers.[^47]For example, prohibitions on maintaining
conflicts of interest were common across all codes, regardless of
professional domain. In the following, we focus less on thematic overlap
and instead on *social actors*and *social actions *explicit or implicit
within the codes, noting 1) where the codes from different domains
diverge and 2) and how each relates to representative virtues or other
forms of ethical behavior.

Social Actors {#social-actors style="text-align: center;"}
-------------

Professional ethics codes often position the individual practitioner as
the primary locus of ethical responsibility.[^48]Individuals are asked
to take the brunt of ethical conflict and adjudicate between potentially
conflicting or incommensurate values.[^49] The codes we examined
followed this pattern, foregrounding the individual practitioner as a
primary social actor through an emphasis on personal responsibility.
Only rarely were codes extended to cover responsibilities of others,
especially those above, around, or below an individual professional.
References to individual professional competence also appear frequently
across both sets of codes: individual professionals are directed to take
on work or perform tasks only within their specific domain (or
sub-domain) of expertise, and to not falsify or misrepresent their
credentials.

What did vary, however, was the scope and range of social actors
considered relevant to a professional context. The absence of
considerations for third parties in most of the codes was notable,
especially for professions where a code's stated professional ethical
commitments could easily conflict with[---]{.emdash}or had evident
impacts on[---]{.emdash}third parties. While a number of the sampled
codes state commitments both to the general public and to the interests
of the employer or profession more narrowly, the morality of a
profession's or an employer's motives are not scrutinized, and the
individual has no guidance on how to navigate moral conflicts. One
exception was the Association of Computer Machinery's ethics code, which
contained explicit provisions around whistleblowing[---]{.emdash}likely
inspired by the historical relationship between computing, state and
corporate surveillance, and privacy harms.[^50]

Other actors[---]{.emdash}sometimes people, other times objects, spaces,
or ideals[---]{.emdash}are evoked across these codes through what we
refer to as "responsibility to" language. At any given time, an
individual professional may have (per their relevant code) a
responsibility to: specific other actors (clients, colleagues, users,
employees, or employers); general others (the public, society, or simply
"others"); a political body (nation, country); specific objects or
ideals (technology, truth, knowledge, the profession); or abstract
spaces or sites (nature). The particular discursive arrangement of these
other actors hints at a given code's imagined scope. Those addressing
only interpersonal or work relationships with colleagues, employers, or
employees could be understood as relatively narrow in scope, suggesting
the body responsible for developing the code either 1) did not imagine
the profession as playing a broad social role or 2) wanted to actively
avoid offering moral guidance on issues beyond the immediate workplace.

Beyond colleagues and employer/employee relationships, some of the
surveyed codes cited specific responsibilities to users (presumably of a
particular system and not of technology generally). This focus was,
unsurprisingly, a common theme in computing and information codes, where
broader ethical commitments were often treated as high-level
abstractions and more precise attention was paid to intra-professional
considerations. Accordingly, social issues and problems of the public
good were often reduced to their most technocratic features. For
example, the Code of Ethics of the American Society for Information
Society & Technology (ASIS&T) begins by urging "its members to be ever
aware of the social, economic, cultural, and political impacts of their
actions or inaction," yet proceeds to detail explicit responsibilities
to employers, clients, and system users[---]{.emdash}and not society
more broadly.

Other information and computing codes also evoked such "general others"
briefly. The IEEE Code of Ethics merely implores professionals "to
accept responsibility in making decisions consistent with the safety,
health, and welfare of the public, and to disclose promptly factors that
might endanger the public or the environment." The Association of
Computing Machinery (ACM) was again an exception, with its code going
into detail regarding "general moral imperatives" and their specific
features. For example, the broad stated obligation to "contribute to
society and human well-being" is followed by the somewhat more precise
imperative to "protect fundamental human rights" and "respect the
diversity of all cultures." While still vague, this explication does
offer some insight into how the ACM conceives of "human well-being."

In contrast to information and computing codes, codes related to
statistics and statistical work consistently foregrounded professional
responsibilities to the public or society. The Statistical Society of
Canada lists responsibilities to society first while the Royal
Statistical Society (UK) singles out "an overriding responsibility to
the public good." The American Statistical Association (ASA) goes the
furthest in making statisticians' responsibility towards society
explicit, averring that "the discipline of statistics links the capacity
to observe with the ability to gather evidence and make decisions,
providing a foundation for building a more informed society." The ASA
also details a set of commitments aiming to limit or reduce the chance
an individual practitioner will be placed in a morally tenuous position
by a third party, for example by "\[striving\] to protect the
professional freedom and responsibility of statistical practitioners,"
especially in cases where "analyses...are known or anticipated to have
tangible physical, financial, or psychological impacts." Further, it
asks employers to "recognize that the results of valid statistical
studies cannot be guaranteed to conform to the expectations or desires
of those commissioning the study or the statistical practitioner(s)."
While the ASA code does not stipulate further ethical commitments the
employer may have, it does to some degree acknowledge and incorporate
the how statistical work interacts with corporate or other institutional
processes.

In addition, these statistics-based ethics codes incorporate ethical
concerns from the broader history and trajectory of research ethics. The
ASA code specifically details an obligation to seek consent, especially
for secondary or indirect uses of data. It also gestures towards
concerns of justice in research ethics, noting, "statistical
descriptions of groups may carry risks of stereotypes and
stigmatization." In response, "statisticians should contemplate, and be
sensitive to, the manner in which information is framed so as to avoid
disproportionate harms to vulnerable groups." Given these codes are
intended to inform statisticians' research practices, it is perhaps
unsurprising the treatment of research subjects would feature
prominently as objects of ethical concern - but makes it all the more
notable that data scientists, who as Beaton notes share a lineage with
both statisticians and psychologists, have yet to fully embrace such
language.[^51]

Codes associated with data metaphors often suggested responsibility to
broadly construed spaces, sites, or ideals through the language of
stewardship. For instance, the Society of American Foresters defines the
forestry profession as "\[serving\] society by fostering stewardship of
the world's forests," while the North American Nature Photography
Association articulates its ethics through principles of stewardship of
and non-interference with various natural habitats. Professions charged
with sanitation, cleanliness, or dealing with hazardous waste also
address environmental concerns. For Certified Hazardous Materials
Managers, the "primary responsibility is to protect the public and the
environment." For the International Sanitary Supply Association (ISSA),
public health is paramount[---]{.emdash}all commercial considerations
are, according to their code of ethics, secondary to this broader
concern.

In contrast to stewardship-based or environmental models, which tend to
refer to objects in the material world, computing and statistics codes
tend to foreground a specific value or ideal and then work to situate
professional ethical responsibilities in service of this higher ideal.
In statistics codes, for example, "truth" and "objective knowledge"
emerge as both quasi-deontological ends-in-themselves and contested
categories professionals must strive to realize in their work. Section A
of the American Statistical Association specifically addresses
statisticians' obligations to reduce, mitigate against, or eliminate
biases[---]{.emdash}either on the part of the professional or the
contracting party[---]{.emdash}which might skew research results. An
ethical statistician, the Code asserts, "uses methodology and data that
are relevant and appropriate, without favoritism or prejudice, and in a
manner intended to produce valid, interpretable, and reproducible
results." The unethical statistician, then, is one who manipulates data
or skews findings in ways that are self-serving or aims to deliberately
mislead or manipulate others.

Finally, there was also variation in the codes with regard to the
positioning of ethics relative to a given professional. In a few cases,
ethics was construed not as a set of commitments, but as constitutive of
professional identity. For example, the code of ethics for the
Association of Information Technology Professionals (AITP) states the
standards set out by the code "are not objectives to be strived for,
they are rules that no true professional will violate." Though seemingly
minor, this difference has consequences for professional identity and
regulation: ethics as professional commitment implies one can remain a
"professional" even when acting in ways potentially construed as
unethical, while, conversely, ethics as constitutive of professional
identity implies that a breach of ethics simultaneously disqualifies
one's status as a professional.

Values and Social Actions {#values-and-social-actions style="text-align: center;"}
-------------------------

Where the previous section focused on actors and objects, this section
focuses on specific values and actions captured or implied in the
surveyed ethics codes. Not only do ethics codes represent an effort to
define and delimit an ideal ethical professional, they also work to
articulate, set, and scope out the sorts of actions and values endemic
to a particular profession. These actions often perform justificatory
work (e.g., positioning certain actions as socially useful helps justify
a profession's existence) or work to stave off certain types of
attention (e.g., clearly stated prohibitions on certain actions may help
deflect public or regulatory scrutiny). Additionally, stated values
reveal something about the anticipated impact of a given
action[---]{.emdash}positioning something as potentially discriminatory,
for example, demonstrates an awareness of a profession's political
impact. In this way, references to specific values or virtues offer
insight into the ethical tenor of actions an individual might be
expected to undertake or account for in their capacity as a
professional.

Within the inventory of values laid out in the codes we analyzed, some
of the starkest divisions came between computing and statistics codes,
and those codes associated with data metaphors. A dominant theme across
all analyzed codes was a proscription against what we term "biopolitical
harms": environmental harms, and the health and safety of
populations.[^52]This emphasis suggests a parallel to the preponderance
of resource-based metaphors for data[---]{.emdash}namely a sense that,
in the abstract, it is easy for professionals to agree to protecting (or
perhaps, managing) the natural world and natural resources, as part of
what Gabriel Abend terms "the moral background" to professionalism
itself.[^53]In contrast, computing codes and statistics codes often
foreground political issues of privacy and freedom of speech, as well as
conceptions of data as confidential and requiring safeguarding. This
attention to privacy, security, and speech grows out of a
longer-standing focus on these areas during the development of
information technology and computing ethics.[^54]Save for limited
references to confidentiality in the codes of The Wildlife Society and
Society of American Foresters, privacy and speech considerations are
absent in our second set of codes.

Given established historical connections between information technology,
communication, and privacy, the emphasis on the latter in computer
science codes makes sense. However, it also points to one of the
starkest differences between the conventional codes and those codes
rooted in our data metaphors: the former tends to foreground abstract
users, rights, and values, while many of the metaphor-based codes
explicitly revolve around material stewardship, public health, and
bodily safety. For example, the Code of Ethics for Hazardous Materials
Managers explicitly states that professionals' "primary responsibility
is to protect the public and the environment," while "the interests of
individual clients and employers must be secondary." In a different way,
the code of ethics for The Wildlife Society places "research and
scientific management of wildlife species, their environments, and
stakeholders" as primary and specifically directs professionals to
educate broadly construed others on these topics. This contrast between
abstract values in the conventional codes and material stewardship in
the metaphor-based codes lends support to the idea that conventional
codes' outsized focus on issues like privacy and
speech[---]{.emdash}themselves heavily informed by the technical rather
than social affordances of computers[---]{.emdash}has limited their
ability to account for a wider range of potential social, political, and
environmental harms.[^55]A focus on natural resources as a site for both
conservation and potential harm also helps professionals avoid the
social complexities and challenges of adjudicating their
responsibilities to society as comprised of other people, instead of a
material background.

Finally, a number of the sampled codes formally prohibit discrimination,
and some others contain explicit lists of those classes of people
deserving of particular protection. However, only the code of ethics for
the National Funeral Directors Association made an explicit connection
between the mission of the profession and a specific vulnerable class of
people.[^56] Specifically, people of low socioeconomic standing or
limited financial means are cited as deserving particular consideration
in view of funeral directors' mission to "to provide families with
meaningful end-of-life services at the highest levels of excellence and
integrity."[^57]This commitment is explicitly accounted for in a
prohibition against withholding services (like delaying the embalming
process) or the body of a loved one (from release to a family or other
legally recognized party) until payment for services has been received.
While clearly rooted in a concern over extortionate business practices
and hucksterism[---]{.emdash}as well as the time sensitive nature of
some features of morticians' work[---]{.emdash}there is, perhaps a
lesson for data scientists here in how to think about specific power
dynamics at play. For example, a code of ethics for data scientists
might be careful to not make certain kinds of data or informational
transparency contingent on an ability to pay or by coercing users to
give up more personal data in the process.

Discussion & Recommendations {#discussion-recommendations style="text-align: center;"}
============================

Our analyses of professional ethics codes from both computer science and
from metaphorically related fields suggest several broad conclusions
relevant to conversations about data in the public sphere, and to data
science as an emerging profession.

First, one of the chief values common to codes from across our sample
was fairness. In the context of computer science ethics, fairness is a
hot topic: computer scientists interested in fairness, accountability,
transparency and other values in machine learning and artificial
intelligence have already begun to interrogate how fairness might be
translated into computational metrics for evaluating algorithms and
systems.[^58]A parallel movement in science and technology studies and
information science has focused on the need to articulate fairness not
only as an allocative metric internal to digital systems, but also as
social one addressing systematic discrimination, bias, and
representational harms.[^59]In the context of professional ethics codes,
however, fairness takes on yet another meaning: as a sign of
interpersonal trust within a profession, and a signal for professional
frankness and honesty.

The strong emphasis on fairness within the conventional codes we sampled
may in fact be connected to the technical definitions of fairness
increasingly prominent in computer science literature: technical systems
are perceived by computer scientists and data scientists as objects
which are the fruit of expert processes of collaboration and
communication, and so those same expert processes would, in theory, be
able to similarly produce technical definitions of
values[---]{.emdash}such as fairness. The strong emphasis on
computational solutions to values questions has much to do with common
areas of professional familiarity, expertise and technical language
among participants. Fairness is a complicated concept in
non-computational contexts as well as computational ones. We argue,
however, a reemphasis on fairness as a social value (in line with
honesty, frankness, and "good faith") would help reorient data science
and related professions towards their broader social role.

The professional codes we sampled[---]{.emdash}from CS and from other
fields[---]{.emdash}are also highly focused on technical and
professional credibility. This second insight is related to our first
point above: professional fairness and honesty are integral to technical
credibility and recognition of expertise. However, scholarly work in the
sociology of trust that observes trust as a social construct is only
partially focused on technical credibility, or whether a person or
institution is able to perform the task they claim they will
do.[^60]While the voluminous literature on trust is too broad to more
than briefly sample here, the other key aspect of social trust is
benevolence: the notion that a trusted person or organization has the
best interests of the trustor at heart.[^61]The emphasis across
professional codes for computer science is credibility, and less so
benevolence.

Given an increasing scholarly and public awareness of the social impacts
of big data, ML, and AI, the lack of attention to social benevolence in
the conventional codes is notable and in need of remedy. Here, insights
rooted in our data metaphors stand to be of particular use. For certain
professions concerned with, for example, sanitation or the handling of
hazardous materials, benevolence (often in the form public or
environmental safety) is paramount[---]{.emdash}it works as an
overarching frame for judgments of professional duty and competence.
Accordingly, we should ask critical questions about how broadly or
narrowly "competence" in particular data scientific projects should be
construed. For example, while a data scientist might have expertise in
particular computational and statistical methods, they may know very
little[---]{.emdash}in the social scientific sense[---]{.emdash}about
the particular communities or behaviors captured in a given dataset.
Interpreting competence in view of social benevolence would require some
knowledge of particular communities, behaviors, or broader social and
political forces (or at least a requirement to contract or seek out
collaborations with other professionals or community members who do
possess such expertise). In certain contexts, it may even be useful to
follow the lead of morticians and funeral directors in codifying
historically-salient social or political groups deserving of particular
consideration. Though not represented in our surveyed codes, the
activist slogan "nothing about us without us" (notably espoused by
disability activists in the United States) may be a useful starting
point for reasoning about data scientists' social obligations.[^62]

In addition, ethical commitments addressing both the employer and the
employed, as well as possible conflicts between those ethical
commitments, are particularly relevant for thinking through the ethics
of data science within large corporate settings. Economic incentives and
ethical commitments to the privacy, security and labor rights of both
data subjects and employees often come into
conflict[^63][---]{.emdash}for example, when data or scientific work
might contribute to the development of military weapons and targeting
systems. How to harmonize broad social commitments with both individual
professional practice and corporate structures in the data science
context[---]{.emdash}especially since, given the heavy reliance on gig
or crowd labor in data science, it remains an open question just who the
individual professional figured across the codes we surveyed might
be[---]{.emdash}is a necessary subject for further research and
activism.[^64]Related conversations around the ethics and governance of
AI provide an instructive parallel case.[^65] Data governance through
the lens of human rights is one possible approach in this vein, though
the suitability and effectiveness of human rights discourse in
mobilizing good corporate governance and change for social justice is an
open question.[^66]

A related insight drawn from our analysis concerns the notion of the
fiduciary, and their "fiduciary duty." A fiduciary is a trustee, and a
fiduciary duty is the legal obligation of one party to act in the best
interest of another. Doctors and lawyers, for instance, have fiduciary
duties to their patients and clients[---]{.emdash}so do other
professionals such wealth managers and morticians. Legal scholars Jack
Balkin and Jonathan Zittrain have recently developed the concept of the
"information fiduciary,"[^67]entailing data scientists and the companies
they work for[---]{.emdash}like Facebook and
Google[---]{.emdash}accepting "the duty to use personal data in ways
that don't betray end users and harm them."[^68]

We see several points from our analysis pertaining to the information
fiduciary model. One is that for the most part, professions with
fiduciary duties protect personal data as a secondary result of their
primary duty of care: to the health of a patient, to (in theory) the law
and justice, to the bodies of the dead. For example, doctors and
morticians, more so than lawyers, are intimately engaged in caring for
us as embodied agents. Standards for trusting doctors and morticians are
thus high: we imagine a doctor, on the average, to be
honest[---]{.emdash}both credible and benevolent[---]{.emdash}in a way
we may not (alas) imagine a computer scientist.

Data scientists and their employers are generally presented as being in
the business of collecting and analyzing data as a primary
goal[---]{.emdash}but this is of course an erroneous view. Data
scientists and computer programmers invariably work in and across
various domains and their work has, in many cases, obvious material
consequences[---]{.emdash}from precision medicine to criminal
sentencing.Here, the emphasis on material stewardship found in
metaphor-based codes of ethics, as opposed to the valorization of
abstract ideals found in many computer science codes, shows how the
material objects of a profession's attention can be obscured by a
profession's conceptual axioms. Data scientists as a profession are
generally associated with abstraction and disembodiment, with numbers
aggregated and immaterial in "the cloud." Yet the real-world
consequences on individual embodied humans of data science can be real,
visceral, and devastating. Likewise, discourses of data as a force, a
resource, and as an industrial product erase the human subjects both of
digital data collection and accumulation and its effects; yet they also
lack the traditions of stewardship and responsibility, which however
imperfectly typify the professional discourses in those fields.

Analogizing digital data as "natural" without stewardship discourses
implicitly signals data - and the living people it involves - are open
for rank exploitation. As Arvind Narayanan argues, "it's not enough to
ask if code executes correctly. We also need to ask if it makes society
better or worse."[^69]The seeming abstraction of data is in some ways
belied by the material metaphors used to describe it: water, oil, and
ore. Yet as Hwang and Levy note, these metaphors, though material,
deflect attention from the fact human data are produced and have impacts
on human beings. We heartily concur with Rebecca Lemov: "'Big data is
people'!"[^70]As such, we argue data scientists should be held to
fiduciary standards closer to those of doctors, morticians, or even
hazardous waste managers[---]{.emdash}they are professionals dealing
with the human bodies and populations in ways that demand a high degree
of both credibility and benevolence. Professional ethics in data science
should include broader, more ecological thinking about the role of data,
computing, and statistical analyses in their social context and
real-world applications.

One final area where professional ethics codes related to data metaphors
differed from those in computer science was around the question of
professional sanction. For instance, the ethical code of the
International Society of Petroleum Engineers has an explicit clause
encouraging practical mitigating action, and also states in the code
itself the mechanism through which members can report violations to the
professional body. If data is indeed the new oil, the IEEE and other
data science codes should be at least as explicit as that of petroleum
engineers in listing consequences for violations of the code and
articulating how those violations can be reported.

As noted above, there is one professional group thematically related to
data science whose professional ethics codes demonstrate a relatively
high degree of sensitivity to a variety of actors, societal values and
broad-based social responsibility: statisticians. Given the centrality
of statistical analysis to data science, we suggest data scientists
could do much worse than having a full-throated professional engagement
with statistical codes of conduct, and with the legacy of statistics as
a tool in social science research. Like data scientists, statisticians
work with many other professions, but nonetheless have articulated their
social obligations. Future scholarship engaging statisticians around the
concept of "fiduciary duty" would be valuable[---]{.emdash}a statistical
fiduciary duty of care is one conceptual way to understand the
professional duties of data scientists and others engaging in data
analysis.

Conclusion {#conclusion style="text-align: center;"}
==========

Our analytic goals in juxtaposing ethics codes in computer science and
related fields alongside codes related to data science metaphors are
threefold. As scholars working at the intersection of information
science, science and technology studies (STS), and the philosophy and
ethics of technology, we have an intellectual interest in tracing the
conceptual connections and sociological themes of computer and data
science, the professions which to a large degree shape the technologies
and social practices around them which we study.  Ethics codes are a
micro-level instantiation of broader structural and institutional values
and debates. These codes represent "the transformation of social
practices into discourses about social practices";[^71]they are not
absolute or perfect representations of these discussions but sites where
certain results of certain political, professional, and material
struggles are stabilized and put to work in the world.

However, we are also concerned with two other, practical normative
outcomes: a statement of the kinds of ethos we as critical scholars want
to see permeate these emerging data cultures; and a concomitant sense of
how data scientists might consider changing existing or nascent
professional ethics codes in data science in light of our findings and
our broader normative commitments.

While many of our proposals are spelled out in the Discussion section
above, we make two more general recommendations for data scientists and
those interested in professional ethics for data science. The first
recommendation is to take "ethics" as a starting point, not as an end.
Codes of ethics increasingly serve to demarcate data culture as a domain
of experts, and conversations around professional ethics in data science
and related fields such as ML/AI are a necessary but absolutely
insufficient condition for the kinds of progressive, just and equitable
social outcomes we seek for the world. Testifying before the US Congress
in 2003 about another new and disruptive technical field,
nanotechnology, STS scholar Langdon Winner noted a historical tendency,
as he saw it, "for those who conduct research about the ethical
dimensions of emerging technology to gravitate toward the more
comfortable, even trivial questions involved, avoiding issues that might
become a focus of conflict."[^72] Digital technologies are powerful
tools: for data scientists to insufficiently engage with the rich social
contexts and disparate, sometimes conflicting human realities of their
use is a lapse of a core ethical obligation, courage, in itself. To
limit conversations about the societal impacts and obligations of data
science solely to professional ethics is a mistake we are keen to have
all parties involved avoid.

Our second recommendation concerns the relationship between professional
ethics codes in data science and data science pedagogy. The ethical
norms of a profession emerge out of every stage of that profession's
training process. As such, we advocate forcefully for data science
education to address not only the professional ethics questions posed by
extant professional codes, but also the societal questions posed by the
metaphors through which the profession, and discourse more broadly,
understands data. These metaphors can serve as what Katie
Shilton[^73]terms "values levers," prompting novel conversations about
data science's impacts and responsibilities to society at large.
Innovative work on broadening the terms of data science education is
already underway.[^74]Data science and data scientists would benefit
from expanding their collaborations with interdisciplinary work in STS,
information studies, and media studies to further reap the benefits of
engaging with values, ethics, and norms at every stage of their
work.[^75]

Finally, our ethical commitments as authors are grounded in a desire for
data justice,[^76]design justice,[^77]as well as the recognition of
historical injustices in emerging data cultures and in society more
broadly. As Kate Crawford has put it, data ethics needs to ask, "What
kind of world do we want to live in?"[^78]We are explicit about these
normative commitments as a way to conceptually tax related ethics codes
and our data metaphors alike. With data-driven online platforms and
digital systems already a potential source of bias and
discrimination,[^79]the processual ethics common to professional codes
need to be supplanted by a more explicit set of norms around data
cultures as spaces for equality and justice[---]{.emdash}within and
beyond a code of ethics for data scientists.

Appendix: List of Professional Ethics Codes Consulted
-----------------------------------------------------

  Organization                                                                                       Date Last Updated   Word Count
  -------------------------------------------------------------------------------------------------- ------------------- ------------
  American Federation of Astrologers (AFA) Code of Ethics                                            No date listed      356
  American Mathematical Society Policy Statement on Ethical Guidelines                               2005                1729
  American Society for Photogrammetry and Remote Sensing Code of Ethics                              No date listed      658
  American Statistical Association (ASA) Ethical Guidelines for Statistical Practice                 2016                3478
  Association for Computing Machinery (ACM) Code of Ethics and Professional Conduct                  1992                3459
  Association for Information Science and Technology (ASIS&T) Professional Guidelines                1992                531
  Association for Information Systems (AIS) Code of Research Conduct                                 2013                4323
  Association of Information Technology Professionals (AITP) Code of Ethics & Standards of Conduct   No date listed      790
  Information Systems Security Association (ISSA) Code of Ethics                                     No date listed      332
  Institute for Certification of Computing Professionals (ICCP) Code of Ethics                       No date listed      2145
  Institute of Electrical and Electronics Engineers (IEEE) Code of Ethics                            No date listed      429
  Institute of Hazardous Materials Management Code of Ethics and Professional Conduct                No date listed      895
  International Society of Petroleum Engineers Code of Ethics                                        2013                561
  National Funeral Directors Association Code of Professional Conduct                                2008                1530
  North American Nature Photography Association                                                      No date listed      465
  Royal Statistical Society                                                                          No date listed      1718
  Society of American Foresters Code of Ethics                                                       2000                833
  Statistical Society of Canada Code of Ethical Statistical Practice                                 No date listed      766
  The Wildlfe Society Code of Ethics                                                                 No date listed      1486
  The Worldwide Cleaning Industry Association                                                        2005                358
  (ISSA) Member Code of Ethics                                                                                           
                                                                                                                         

[![Creative Commons
License](88x31.png "https://i.creativecommons.org/l/by/4.0/88x31.png")](http://creativecommons.org/licenses/by/4.0/)\
Unless otherwise specified, all work in this journal is licensed under
a [Creative Commons Attribution 4.0 International
License](http://creativecommons.org/licenses/by/4.0/).
:::
:::

[^1]: Brian Beaton, Amelia Acker, Lauren Di Monte, Shivrang Setlur,
    Tonia Sutherland, and Sarah E Tracy, "Debating Data Science,"
    *Radical History Review *2017, no. 127 (March 2, 2017): 133-48.
    doi:10.1215/01636545-3690918.

[^2]: Brian Beaton, "How to Respond to Data Science: Early Data
    Criticism by Lionel Trilling," *Information & Culture: a Journal of
    History *51, no. 3 (August 2016): 352-72. doi:10.7560/IC51303.

[^3]: "Code of Ethics," *Data for Democracy*, accessed June 2, 2018,
    http://datafordemocracy.org/projects/ethics.html.

[^4]: For an analysis of ethics statements in the AI context, see Daniel
    Greene, Anna Lauren Hoffmann, and Luke Stark (forthcoming),
    \"[Better, nicer, clearer, fairer: A critical assessment of the
    movement for ethical artificial intelligence and machine
    learning](http://dmgreene.net/wp-content/uploads/2018/11/Greene-Hoffmann-Stark-Better-Nicer-Clearer-Fairer-HICSS-Final-Submission.pdf),\"
    52nd Hawaii International Conference on Systems Science.

[^5]: Kath Albury et al., "Data Cultures of Mobile Dating and Hook-Up
    Apps: Emerging Issues for Critical Social Science Research," *Big
    Data & Society *4, no. 2 (July 3, 2017): 205395171772095-11, 135,
    doi:10.1177/2053951717720950.

[^6]: Harold L Wilensky, "The Professionalization of Everyone?,"
    *American Journal of Sociology *70, no. 2 (September 1964): 137-58.

[^7]: Abbott, "Professional Ethics," 856.

[^8]: Abbott, "Professional Ethics."

[^9]: Jacob Metcalf, "Ethics Codes: History, Context, and Challenges,"
    *Council for Big Data, Ethics, and Society*, November 9, 2014.

[^10]: Metcalf, "Ethics Codes: History, Context, and Challenges," 863.

[^11]: Frankel, "Professional Codes: Why, How, and with What Impact?"

[^12]: Frankel, "Professional Codes: Why, How, and with What Impact?,"
    109.

[^13]: Heinz C. Luegenbiehl, "Codes of Ethics and the Moral Education of
    Engineers," *Business Professional Ethics Journal*2, no. 4 (1983):
    41-61.

[^14]: Michael Davis, "Thinking Like an Engineer: the Place of a Code of
    Ethics in the Practice of a Profession," *Philosophy & Public
    Affairs *20, no. 2 (1991): 150-67.

[^15]: Effy Oz, "Ethical Standards for Computer Professionals: a
    Comparative Analysis of Four Major Codes," *Journal of Business
    Ethics *12, no. 9 (September 1993): 709-26.

[^16]: Metcalf, "Ethics Codes: History, Context, and Challenges."

[^17]: Metcalf, "Ethics Codes: History, Context, and Challenges."

[^18]: Oz,"Ethical Standards for Computer Professionals: a Comparative
    Analysis of Four Major Codes."

[^19]: Don Gotterbarn and James H Moor, "Virtual Decisions: Video Game
    Ethics, Just Consequentialism, and Ethics on the Fly," *SIGCAS
    Computers and Society *39, no. 3 (December 2009): 27-42.

[^20]: Rob Kitchin, "Big Data, New Epistemologies and Paradigm Shifts,"
    *Big Data & Society *1, no. 1 (April 2014): 205395171452848-12,
    doi:10.1177/2053951714528481.

[^21]: Mark Nunes, "Baudrillard in Cyberspace: Internet, Virtuality, and
    Postmodernity," *Style *29 (1995): 314-27; Sally Wyatt, "Danger!
    Metaphors at Work in Economics, Geophysiology, and the Internet,"
    *Science, Technology, & Human Values *29, no. 2 (August 18, 2016):
    242-61, doi:10.1177/0162243903261947; Rowan Wilken, "An Exploratory
    Comparative Analysis of the Use of Metaphors in Writing on the
    Internet and Mobile Phones," *Social Semiotics *23, no. 5 (November
    2013): 632-47,
    https://towardsdatascience.com/big-data-metaphors-we-live-by-98d3fa44ebf8.

[^22]: as Teun A. van Dijk,"Principles of Critical Discourse Analysis,"
    *Discourse & Society*4, no. 2 (1993): 249-83; "Critical Discourse
    Analysis," in *The Handbook of Discourse Analysis*, (West Sussex,
    UK: Wiley, 2015), 466-85.

[^23]: van Dijk, "Critical Discourse Analysis," 473.

[^24]: Rowan Wilken, "An Exploratory Comparative Analysis of the Use of
    Metaphors in Writing on the Internet and Mobile Phones,"*Social
    Semiotics *23, no. 5 (November 2013): 632-47,
    doi:10.1080/10350330.2012.738999.

[^25]: Wilken,"An Exploratory Comparative Analysis," 642.

[^26]: Dawn Nafus,"Stuck Data, Dead Data, and Disloyal Data: the Stops
    and Starts in Making Numbers Into Social Practices," *Distinktion:
    Journal of Social Theory *15, no. 2 (June 17, 2014): 208-22,
    doi:10.1080/1600910X.2014.920266.

[^27]: Stewart Brand, *The Media Lab*, (New York: Viking Penguin, 1987),
    202.

[^28]: Cornelius Puschmann and Jean Burgess, "Big Data, Big Questions\|
    Metaphors of Big Data," *International Journal of Communication *8
    (2014).

[^29]: Puschmann and Burgess, "Big Data, Big Questions," 1700.

[^30]: Puschmann and Burgess, "Big Data, Big Questions," 1699.

[^31]: The now-ubiquitous metaphor of "cloud" computing has similar
    resonances, though it captures data as
    vaporous[---]{.emdash}somewhere between an invisible gas and a
    suffocating liquid.

[^32]: Deborah Lupton, \"[Swimming or Drowning in the Data Ocean?
    Thoughts on the Metaphors of Big
    Data](https://simplysociology.wordpress.com/2013/10/29/swimming-or-drowning-in-the-data-ocean-thoughts-on-the-metaphors-of-big-data/),\"
    *The Sociological Life*, October 29, 2013.

[^33]: Sara M. Watson, "Metaphors of Big Data," *DIS Magazine*, May 28,
    2016.

[^34]: Kailash Awati and Simon Buckingham Shum, \"[Big Data Metaphors We
    Live
    by](https://medium.com/@sbskmi/big-data-metaphors-we-live-by-79ba2fbd1423),\"
    *Towards Data Science*, May 14, 2015.

[^35]: Cory Doctorow, \"[Why Personal Data Is Like Nuclear
    Waste](https://www.theguardian.com/technology/2008/jan/15/data.security),\"
    *The Guardian*, January 15, 2008.)Metaphors referencing more
    quotidian forms of waste also point toward the similarly quotidian
    forms of work involved in data science: are those who work with data
    "rock stars" or "data janitors"[---]{.emdash}or both?((Lilly Irani,
    \"[Justice for 'Data
    Janitors'](http://www.publicbooks.org/justice-for-data-janitors/),\"
    *Public Books*, January 15, 2015.

[^36]: There is one notable[---]{.emdash}and
    noxious[---]{.emdash}analogy which does foreground people: "big data
    is like teenage sex: everyone talks about it, nobody really knows
    how to do it, everyone thinks everyone else is doing it, so everyone
    claims they are doing it...." Posted to Facebook in 2013 by Dan
    Ariely, Professor at Duke University, the phrase has since been
    popularized in numerous blog posts, news articles, and talks. We
    have deliberately omitted this analogy, however, as we find it more
    problematic than insightful. Specifically, we do not wish to
    contribute to the sexualization of technological work[---]{.emdash}a
    process \* often serves to exclude or marginalize women in
    STEM[---]{.emdash}or engage in the belittling of young persons'
    sexual development. While other work may find constructive
    connections between sexual ethics and data ethics broadly (see, for
    example, work on the ethics of consent: Una Lee and Dann Toliver,
    *[Building Consentful Tech](http://ripplemap.io/zine.pdf),* Toronto,
    ON: And Also Too, 2017.), we do not find this particular analogy
    productive.

[^37]: Hwang and Levy, "'The Cloud' and Other Dangerous Metaphors."

[^38]: Kavita Philip, "Nature, Culture Capital, Empire," *Capitalism
    Nature Socialism *18, no. 1 (March 2007): 5-12,
    doi:10.1080/10455750601164584.

[^39]: Irina Raicu, \"[Metaphors of Big
    Data](http://on.recode.net/1PnhhgD),\" *Recode*, February 26, 2016.

[^40]: The CSEP's Ethics Code Collection is available at
    http://ethicscodescollection.org. For further information on the
    CSEP's collection and update policy, please see
    <http://ethics.iit.edu/ecodes/node/5421>.

[^41]: Jeff Hammerbacher, "Information Platforms and the Rise of the
    Data Scientist," in *Beautiful Data: the Stories Behind Elegant Data
    Solutions*, ed. Toby Segaran and Jeff Hammerbacher, (Sebastopol, CA,
    2009), 73-84.

[^42]: Oliver L. Haimson and Anna Lauren Hoffmann, "Constructing and
    Enforcing 'Authentic' Identity Online: Facebook, Real Names, and
    Non-Normative Identities," *First Monday *21, no. 6 (June 6, 2016),
    doi: <http://dx.doi.org/10.5210/fm.v21i6.6791>; Anna Lauren
    Hoffmann, Nicholas Proferes, and Michael Zimmer, "'Making the World
    More Open and Connected': Mark Zuckerberg and the Discursive
    Construction of Facebook and Its Users," *New Media & Society *12,
    no. 1 (January 13, 2017): 146144481666078-20,
    doi:10.1177/1461444816660784.

[^43]: Maude Standish, \"[Data Is the New
    Astrology](https://www.huffingtonpost.com/maude-standish/data-is-the-new-astrology_b_3150148.html),\"
    *The Huffington Post*, April 25, 2013; Kate Crawford, "Asking the
    Oracle," in *Laura Poitras: Astro Noise*, (New York/New Haven, CT,
    2016), 138-53.

[^44]: Theo van Leeuwen, *Discourse and Practice: New Tools for Critical
    Discourse Analysis *(Oxford Studies in Sociolinguistics), Oxford:
    Oxford University Press, 2008.

[^45]: van Dijk, "Critical Discourse Analysis," 466.

[^46]: H. F. Hsieh, "Three Approaches to Qualitative Content Analysis,"
    *Qualitative Health Research *15, no. 9 (November 1, 2005): 1277-88,
    doi:10.1177/1049732305276687.

[^47]: Gaumnitz and Lere, "A Classification Scheme for Codes of Business
    Ethics."

[^48]: Abbot, "Professional Ethics."

[^49]: Ethics codes thus perform for professionals in the abstract what
    the interaction design of many digital platforms does for gig
    workers in practice: figure their subjects as "moral liability
    sponges" or "moral crumple zones." See Alex Rosenblat and Luke
    Stark, "Algorithmic Labor and Information Asymmetries: a Case Study
    of Uber's Drivers," *The International Journal of Communication *10
    (July 27, 2016): 3758-84; and M. C. Elish, "Moral Crumple Zones:
    Cautionary Tales in Human-Robot Interaction" (We Robot 2016) (March
    20, 2016). We Robot 2016 Working Paper. Available at SSRN:
    <https://ssrn.com/abstract=2757236> or
    <http://dx.doi.org/10.2139/ssrn.2757236>

[^50]: David Lyon, ed., *Surveillance as Social Sorting: Privacy, Risk
    and Digital Discrimination*, (New York: Routledge, 2003); Herman
    Tavani, "Privacy Enhancing Technologies as a Panacea for Online
    Privacy Concerns: Some Ethical Considerations," *Journal of
    Information Ethics *9, no. 2 (2000); Helen Nissenbaum, "Respecting
    Context to Protect Privacy: Why Meaning Matters," *Science and
    Engineering Ethics *109, no. 4 (July 11, 2015): 1-22,
    doi:10.1007/s11948-015-9674-9.

[^51]: Brian Beaton, "How to Respond to Data Science: Early Data
    Criticism by Lionel Trilling," *Information & Culture: a Journal of
    History *51, no. 3 (August 2016): 352-72. doi:10.7560/IC51303.

[^52]: Patricia Ticineto Clough and Craig Willse, "Gendered
    Security/National Security: Political Branding and Population
    Racism," March 7, 2013; Michel Foucault Collège de France, *The
    Birth of Biopolitics: Lectures at the Collège De France, 1978-1979*,
    1st ed., (New York: Picador, 2010); Matthew B Sparke, "A Neoliberal
    Nexus: Economy, Security and the Biopolitics of Citizenship on the
    Border," *Political Geography *no. 25, no. 25 (2006): 151-80,
    doi:10.1016/j.polgeo.2005.10.002.

[^53]: Gabriel Abend, *The Moral Background* (Princeton, NJ and Oxford:
    Princeton University Press, 2014).

[^54]: Tavani, "The State of Computer Ethics as a Philosophical Field of
    Inquiry;" Frances S. Grodzinsky and Herman T. Tavani, "Applying the
    'Contextual Integrity' Model of Privacy to Personal Blogs in the
    Blogosphere," *International Journal of Internet Research Ethics *3
    (December 30, 2010): 38-47; Lucas D. Introna, "Maintaining the
    Reversibility of Foldings: Making the Ethics (Politics) of
    Information Technology Visible," *Ethics and Information
    Technology *9, no. 1 (December 21, 2006): 11-25,
    doi:10.1007/s10676-006-9133-z.

[^55]: Literature on the concept of "securitization" supports this view:
    when topics of public debate are securitized, they are removed from
    the realm of political contestation and deemed to be technical
    matters addressable by experts. See Lene Hansen and Helen
    Nissenbaum, "Digital Disaster, Cyber Security, and the Copenhagen
    School," *International Studies Quarterly *53 (2009): 1155-75; Helen
    Nissenbaum, "Where Computer Security Meets National Security,"
    *Ethics and Information Technology *7 (2005): 61-73,
    doi:10.1007/s10676-005-4582-3.

[^56]: It is worth noting that The Wildlife Society does address
    unspecified "stakeholders" in the well-being of certain wildlife
    species. These stakeholders could easily include oppressed
    individuals or groups deserving of particular consideration,
    especially native or indigenous peoples. However, these groups are
    not specifically named in the code.

[^57]: \"[About NFDA](http://www.nfda.org/about-nfda),\" *National
    Funeral Directors Association*, June 9, 2018.

[^58]: Solon Barocas and Andrew D. Selbst, "Big Data's Disparate
    Impact," California Law Review 104 (2016): 671-732.
    doi:10.15779/Z38BG31; Chelsea Barabas, Madars Virza, Karthik
    Dinakar, Joichi Ito, and Jonathan Zittrain, "Interventions Over
    Predictions - Reframing the Ethical Debate for Actuarial Risk
    Assessment," Proceedings of Machine Learning Research 81:1-15, 2018.

[^59]: Anna Lauren Hoffmann, "Data Violence and How Bad Engineering
    Choices Can Damage Society," *Medium *(Member Feature Story), 30
    April 2018, available at
    <https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4>

[^60]: Linda D. Molm, Nobuyuki Takahashi, and Gretchen Peterson, "Risk
    and Trust in Social Exchange: an Experimental Test of a Classical
    Proposition," *The American Journal of Sociology *105, no. 5 (March
    2000): 1396-1427; Susan P. Shapiro, "The Social Control of
    Impersonal Trust," *American Journal of Sociology *93, no. 3
    (November 1987): 623-58; Guido Möllering, "The Trust/Control
    Duality," *International Sociology *20, no. 3 (June 29, 2016):
    283-305, doi:10.1177/0268580905055478.

[^61]: Matthew K. O. Lee and Efraim Turban, "A Trust Model for Consumer
    Internet Shopping," *International Journal of Electronic
    Commerce *6, no. 1 (October 1, 2001): 75-91,
    doi:10.2307/27751003?ref=search-gateway:65426dfa915042907ae6237cf88297e1;
    David Gefen, Izak Benbasat, and Paula Pavlou, "A Research Agenda for
    Trust in Online Environments," *Journal of Management Information
    Systems *24, no. 4 (May 12, 2008): 275-86,
    doi:10.2753/MIS0742-1222240411.

[^62]: James I. Charlton, *Nothing About Us Without Us: Disability
    Oppression and Empowerment*, (Berkeley and Los Angeles: University
    of California Press, 1998).

[^63]: Noëmi Manders-Huits and Michael Zimmer, "Values and Pragmatic
    Action: The Challenges of Introducing Ethical Intelligence in
    Technical Design Communities," *International Review of Information
    Ethics*, January 30, 2009, 1-8.

[^64]: Kate Conger, \"[Google Plans Not to Renew Its Contract for
    Project Maven, a Controversial Pentagon Drone AI Imaging
    Program](https://gizmodo.com/google-plans-not-to-renew-its-contract-for-project-mave-1826488620),\"
    *Gizmodo*, June 1, 2018.

[^65]: Daniel Greene, Anna Lauren Hoffmann, and Luke Stark, "Better,
    Nicer, Clearer, Fairer: A Critical Assessment of the Movement for
    Ethical Artificial Intelligence and Machine Learning," Hawaii
    International Conference on System Sciences (HICSS 2019), Maui, HI.

[^66]: Mark Latonero, *Governing Artificial Intelligence: Upholding
    Human Rights and Dignity*, Data & Society Research Institute, (10
    October 2018), available at
    https://datasociety.net/output/governing-artificial-intelligence/;
    Ron Dudai, "Human Rights in the Populist Era: Mourn then
    (Re)Organize," *Journal of Human Rights Practice *9, no. 1 (February
    2017): 16-21. <https://doi.org/10.1093/jhuman/hux005>

[^67]: Jack M. Balkin, "Information Fiduciaries and the First
    Amendment," *UC Davis Law Review *49, no. 4 (April 2016): 1183-1234.

[^68]: Jack M. Balkin and Jonathan Zittrain, \"[A Grand Bargain to Make
    Tech Companies
    Trustworthy](https://www.theatlantic.com/technology/archive/2016/10/information-fiduciary/502346/),\"
    *The Atlantic*, October 3, 2016.

[^69]: Doug Hulette, \"[Patrolling the Intersection of Computers and
    People](https://www.cs.princeton.edu/news/patrolling-intersection-computers-and-people),\"
    *Princeton University Computer Science*, October 2, 2017.

[^70]: Rebecca Lemov, \"'[Big data is
    people!](https://aeon.co/essays/why-big-data-is-actually-small-personal-and-very-human)'\"
    *Aeon Magazine*, June 16, 2016.

[^71]: Theo van Leeuwen*, Discourse and Practice: New Tools for Critical
    Discourse Analysis *(Oxford Studies in Sociolinguistics), Oxford:
    Oxford University Press, 2008, 105.

[^72]: Langdon Winner, Testimony to the Committee on Science of the U.S.
    House of Representatives on The Societal Implications of
    Nanotechnology, 9 April 2003, available at
    <http://homepages.rpi.edu/~winner/testimony.htm>.

[^73]: Katie Shilton,"Values Levers: Building Ethics Into Design,"
    *Science, Technology, & Human Values *38, no. 3 (May 2013): 374-97,
    doi:10.1177/0162243912436985.

[^74]: Michael Skirpan et al., "Ethics Education in Context," (the 49th
    ACM Technical Symposium, New York, New York, USA: ACM Press, 2018),
    940-45, doi:10.1145/3159450.3159573; \[Author, 2018\];
    Costanza-Chock, "Design Justice: Towards an Intersectional Feminist
    Framework for Design Theory and Practice."

[^75]: Mary Flanagan and Helen Nissenbaum, *Values at Play in Digital
    Games*, (Cambridge, MA: The MIT Press, 2014); Phoebe Sengers et al.,
    "Reflective Design," (Proceedings of the 4th Decennial Aarhus
    Conference, Aarhus, Denmark, 2005), 49-58; Batya Friedman, Peter H.
    Kahn, and Alan Borning, "Value Sensitive Design and Information
    Systems," in *Human-Computer Interaction in Management Information
    Systems: Foundations*, ed. B. Schneiderman, Ping Zhang, and D.
    Galletta, (New York: M.E. Sharpe, Inc., 2006), 348-72.

[^76]: Hoffmann, "Data Violence."

[^77]: Sasha Costanza-Chock, "Design Justice: Towards an Intersectional
    Feminist Framework for Design Theory and Practice," 2018, 1-14,
    doi:10.21606/dma.2017.679.

[^78]: Kate Crawford, "AI Now: Social and Political Questions for
    Artificial Intelligence," (University of Washington, March 6, 2018),
    available at: <https://www.youtube.com/watch?v=a2IT7gWBfaE>.

[^79]: Batya Friedman and Helen Nissenbaum, "Bias in Computer Systems,"
    *ACM Transactions on Information Systems *14, no. 3 (September 5,
    1996): 330-47; Joy Buolamwini and Timnit Gebru, "Gender Shades:
    Intersectional Accuracy Disparities in Commercial Gender
    Classification," *Proceedings of Machine Learning Research *81
    (2018): 1-15.
